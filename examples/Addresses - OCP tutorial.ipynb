{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addresses Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goals for this notebook is to perform the following tasks on a dataset with Addresses:\n",
    "- Load\n",
    "- Tokenize into encoded types\n",
    "    - Basic\n",
    "    - Advanced\n",
    "- Collect\n",
    "- Align\n",
    "- Generate Patterns\n",
    "- Identify Anomalies\n",
    "- Evaluate other address columns on a pattern\n",
    "- Abstraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "We're using a dataset with two addresse columns. Let's combine to get a full, more complicated column and drop any row with nulls. For the purposes of this example, we shall detect patterns from all distinct values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>Address Continued</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13945</th>\n",
       "      <td>14200 SOUTHEAST MCLOUGHLIN BOULEVARD</td>\n",
       "      <td>SUITE K</td>\n",
       "      <td>14200 SOUTHEAST MCLOUGHLIN BOULEVARD|SUITE K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>15642 NE GLISAN STREET</td>\n",
       "      <td>#1</td>\n",
       "      <td>15642 NE GLISAN STREET|#1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11379</th>\n",
       "      <td>5305 RIVER RD NORTH</td>\n",
       "      <td>STE B</td>\n",
       "      <td>5305 RIVER RD NORTH|STE B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1711</th>\n",
       "      <td>742 SW VISTA AVE</td>\n",
       "      <td>APT 42</td>\n",
       "      <td>742 SW VISTA AVE|APT 42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8864</th>\n",
       "      <td>2025 NE 42ND AVE</td>\n",
       "      <td>APT 205</td>\n",
       "      <td>2025 NE 42ND AVE|APT 205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Address  Address Continued  \\\n",
       "13945  14200 SOUTHEAST MCLOUGHLIN BOULEVARD           SUITE K   \n",
       "4672                 15642 NE GLISAN STREET                #1   \n",
       "11379                   5305 RIVER RD NORTH             STE B   \n",
       "1711                       742 SW VISTA AVE            APT 42   \n",
       "8864                       2025 NE 42ND AVE           APT 205   \n",
       "\n",
       "                                            Address  \n",
       "13945  14200 SOUTHEAST MCLOUGHLIN BOULEVARD|SUITE K  \n",
       "4672                      15642 NE GLISAN STREET|#1  \n",
       "11379                     5305 RIVER RD NORTH|STE B  \n",
       "1711                        742 SW VISTA AVE|APT 42  \n",
       "8864                       2025 NE 42ND AVE|APT 205  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address = pd.read_csv('../resources/dev/urban.csv', usecols=['Address ', 'Address Continued']).dropna(how='any')\n",
    "address['Address'] = address['Address '].fillna('')+ '|' + address['Address Continued'].fillna('')\n",
    "address.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2711, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are ~2700 values\n",
    "address.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "968"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with 968 unique addresses to detect dominant patterns from\n",
    "address_unique = address['Address'].unique()\n",
    "len(address_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize\n",
    "\n",
    "Splitting the values into basic and advanced types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean_pattern.tokenize.regex import DefaultTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('c',\n",
       " '/',\n",
       " 'o',\n",
       " ' ',\n",
       " 'pnc',\n",
       " ' ',\n",
       " 'real',\n",
       " ' ',\n",
       " 'estate',\n",
       " ' ',\n",
       " 'tax',\n",
       " ' ',\n",
       " 'credit',\n",
       " ' ',\n",
       " 'capital',\n",
       " '|',\n",
       " '121',\n",
       " ' ',\n",
       " 'sw',\n",
       " ' ',\n",
       " 'morrison',\n",
       " ' ',\n",
       " 'street',\n",
       " ' ',\n",
       " 'suite',\n",
       " ' ',\n",
       " '1300')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The default tokenizer shall split it on all punctuation, keeping '.'s intact if the \n",
    "# punctuation flag is set to true.\n",
    "\n",
    "dt = DefaultTokenizer()\n",
    "dt.tokenize(address_unique)[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Types\n",
    "With no type resolvers attached, the tokenizer shall convert each token to a supported basic datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(_'ALPHA'_(1,'c'),\n",
       " _'PUNC'_(1,'/'),\n",
       " _'ALPHA'_(1,'o'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(3,'pnc'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(4,'real'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(6,'estate'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(3,'tax'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(6,'credit'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(7,'capital'),\n",
       " _'PUNC'_(1,'|'),\n",
       " _'NUMERIC'_(3,'121'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(2,'sw'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(8,'morrison'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(6,'street'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(5,'suite'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'NUMERIC'_(4,'1300'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For use with the proceeding components, we convert the tokens into an internal Token representation\n",
    "encoded = dt.encode(address_unique)\n",
    "encoded[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_'NUMERIC'_(4,'1741')\n",
      "regex_type: SupportedDataTypes.ALPHA\n",
      "size: 1\n",
      "value: c\n",
      "rowidx: 8\n"
     ]
    }
   ],
   "source": [
    "# Each tuple in the list represents a row with each element inside the tuple, a Token Element. Each token element \n",
    "# maintains a bunch of profiling information which is later aggregated into patterns, anomalies, profiles etc.\n",
    "print(encoded[5][0])\n",
    "for v, item in vars(encoded[8][0]).items():\n",
    "    print('{}: {}'.format(v, item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced Types\n",
    "Here we attach an Address type resolver to a Tokenizer, which enables us to identify more complex tokens such as 'Street', 'Ave', 'Apt' etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean_pattern.datatypes.resolver import AddressDesignatorResolver, DefaultTypeResolver\n",
    "from openclean_pattern.tokenize.regex import RegexTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default type resolver identifies basic types, and adding an address resolver shall empower it use a \n",
    "# a repository of master data to identify specialized tokens by building a prefix tree\n",
    "\n",
    "tr = DefaultTypeResolver(interceptors=AddressDesignatorResolver())\n",
    "rt = RegexTokenizer(type_resolver=tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(_'ALPHA'_(1,'c'),\n",
       " _'PUNC'_(1,'/'),\n",
       " _'ALPHA'_(1,'o'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(3,'pnc'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(4,'real'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'STREET'_(6,'estate'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(3,'tax'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(6,'credit'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(7,'capital'),\n",
       " _'PUNC'_(1,'|'),\n",
       " _'NUMERIC'_(3,'121'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(2,'sw'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(8,'morrison'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'STREET'_(6,'street'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'SUD'_(5,'suite'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'NUMERIC'_(4,'1300'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We see now there exist internal representations for _STREET_ and a _SUD_ (secondary address designator) tokens\n",
    "address_encoded = rt.encode(address_unique)\n",
    "address_encoded[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect\n",
    "We aim to collect similar looking rows with each other using each token's regex_type and it's position as variables to calculate proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean_pattern.align.cluster import Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster uses a DBSCAN clusterer to calculate the distance between encoded rows and group them into clusters.\n",
    "# Here we use the tree-edit-distance to compute proximity\n",
    "clusters = Cluster(dist='TED', min_samples=50).collect(address_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "403\n",
      "2571               550 CALIFORNIA AVE|STE 200\n",
      "3354        1580 NE 32ND AVENUE|APARTMENT 415\n",
      "5835    533 NORTHEAST HOLLADAY STREET|APT 304\n",
      "9667           243 S 2ND ST|C/O SHANNON SOUZA\n",
      "1673                7885 SW VLAHOS DR|APT 106\n",
      "Name: Address, dtype: object\n",
      "\n",
      "2\n",
      "59\n",
      "8305               545 MERIDIAN AVE|STE D #26787\n",
      "5686                   5305 RIVER RD NORTH|STE B\n",
      "8658               707 SW WASHINGTON ST|STE 1500\n",
      "8014    16123 LOWER HARBOR ROAD|GENERAL DELIVERY\n",
      "4669                   15642 NE GLISAN STREET|#1\n",
      "Name: Address, dtype: object\n",
      "\n",
      "1\n",
      "67\n",
      "8204          5125 SW SCHOLLS FERRY RD|34\n",
      "4887         18423 NW CHEMEKETA LN|UNIT B\n",
      "8983    38100 SANDY HEIGHTS ST|APT # L135\n",
      "1407              235 FRONT ST SE|STE 400\n",
      "9049        2050 GOODPASTURE LOOP|APT 141\n",
      "Name: Address, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We discover 3 different patterns with atleast 50 values\n",
    "for cluster in clusters:\n",
    "    if cluster != -1:\n",
    "        print(cluster)\n",
    "        print(len(clusters[cluster]))\n",
    "        print(address.iloc[list(clusters[0])]['Address'].sample(5))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align\n",
    "Next, for the identified groups, we add Gap characters i.e. align the such that each group has the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean_pattern.align.pad import Padder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(_'ALPHA'_(1,'c'),\n",
       " _'PUNC'_(1,'/'),\n",
       " _'ALPHA'_(1,'o'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(3,'pnc'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(4,'real'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'STREET'_(6,'estate'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(3,'tax'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(6,'credit'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(7,'capital'),\n",
       " _'PUNC'_(1,'|'),\n",
       " _'NUMERIC'_(3,'121'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(2,'sw'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(8,'morrison'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'STREET'_(6,'street'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'SUD'_(5,'suite'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'NUMERIC'_(4,'1300'),\n",
       " _'G'_(0,''))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The padder appends n gap Tokens to each row where n is the difference between the longest row in the column and\n",
    "# the current row\n",
    "pd = Padder()\n",
    "tokens = pd.align(address_encoded, clusters)\n",
    "tokens[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Patterns\n",
    "We analyse each cluster of aligned rows and generate an Openclean Pattern object. Pattern generation can either be row-wise, i.e. all rows with the same tokens are aggregated into one pattern, or column-wise, i.e. tokens at each position in rows are pooled to retrieve the most common token type per position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean_pattern.regex.compiler import DefaultRegexCompiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n",
      "0 : RowPatterns(NUMERIC(1-5) \\S() ALPHA(1-11) \\S() ALPHA(1-13) \\S() STREET(2-9) PUNC(|) SUD(2-9) \\S() NUMERIC(1-5))\n",
      "\n",
      "32\n",
      "2 : RowPatterns(NUMERIC(2-5) \\S() ALPHA(1-11) \\S() ALPHA(2-11) \\S() STREET(2-6) PUNC(|#) PUNC(#) NUMERIC(1-4))\n",
      "\n",
      "67\n",
      "1 : RowPatterns(NUMERIC(1-5) \\S() ALPHA(1-13) \\S() STREET(2-9) PUNC(|) SUD(3-5) \\S() NUMERIC(1-4))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the column method pools the majority token type from each token position across the rows. We discover\n",
    "# that 174 values follow cluster 0, 32 follow cluster 2 and 67 follow cluster 1\n",
    "\n",
    "rc = DefaultRegexCompiler(method='col', per_group='all')\n",
    "patterns = rc.compile(address_encoded, clusters)\n",
    "\n",
    "for cluster, pattern in patterns.items():\n",
    "    if cluster != -1:\n",
    "        print('{}'.format(pattern.top(1, pattern=True).freq))\n",
    "        print('{} : {}'.format(cluster, pattern))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Anomalies\n",
    "We identify anomalies in the column. i.e. values in each group/cluster that didn't match the dominant(top) pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 171\n",
      "RowPatterns(NUMERIC(1-5) \\S() ALPHA(1-11) \\S() ALPHA(1-13) \\S() STREET(2-9) PUNC(|) SUD(2-9) \\S() NUMERIC(1-5))\n",
      "\n",
      "5686                            5305 RIVER RD NORTH|STE B\n",
      "7339                           13000 NW CORNELL RD|APT 15\n",
      "10469    ATTN OFFICE FACILITIES JONES|3601 SW MURRAY BLVD\n",
      "8297                            5305 RIVER RD NORTH|STE B\n",
      "8269                          528 WEST 10TH AVENUE|APT #1\n",
      "Name: Address, dtype: object\n",
      "\n",
      "2 23\n",
      "RowPatterns(NUMERIC(2-5) \\S() ALPHA(1-11) \\S() ALPHA(2-11) \\S() STREET(2-6) PUNC(|#) PUNC(#) NUMERIC(1-4))\n",
      "\n",
      "1269          1051C NE 6TH STREET|SUITE 1C\n",
      "9816             5305 RIVER RD NORTH|STE B\n",
      "7995    101 SOUTHWEST MADISON STREET|#8352\n",
      "9650                 2936 WILLAMETTE ST|10\n",
      "1280          1051C NE 6TH STREET|SUITE 1C\n",
      "Name: Address, dtype: object\n",
      "\n",
      "1 0\n",
      "RowPatterns(NUMERIC(1-5) \\S() ALPHA(1-13) \\S() STREET(2-9) PUNC(|) SUD(3-5) \\S() NUMERIC(1-4))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "anoms = rc.anomalies(encoded, clusters)\n",
    "for an in anoms:\n",
    "    if an != -1:\n",
    "        print(an, len(anoms[an]))\n",
    "        print(patterns[an])\n",
    "        if len(anoms[an]) > 0:\n",
    "            print()\n",
    "            print(address.iloc[anoms[an]]['Address'].sample(5))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PattenFinder Abstraction\n",
    "A PatternFinder object can be built with all the above components to easily detect patterns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean_pattern.opencleanpatternfinder import OpencleanPatternFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sequence of operations remains the same, i.e.: \n",
    "# sampling -> type resolution + tokenization -> collection -> alignment -> compilation\n",
    "\n",
    "pf = OpencleanPatternFinder(\n",
    "    distinct=True,\n",
    "    frac=1,\n",
    "    tokenizer=RegexTokenizer(\n",
    "        type_resolver=DefaultTypeResolver(\n",
    "            interceptors=AddressDesignatorResolver()\n",
    "        )\n",
    "    ),\n",
    "    collector=Cluster(dist='TED', min_samples=50),\n",
    "    aligner=Padder(),\n",
    "    compiler=DefaultRegexCompiler(method='col', per_group='all')\n",
    ")\n",
    "patterns = pf.find(address['Address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n",
      "0 : RowPatterns(NUMERIC(1-5) \\S() ALPHA(1-11) \\S() ALPHA(1-13) \\S() STREET(2-9) PUNC(|) SUD(2-9) \\S() NUMERIC(1-5))\n",
      "\n",
      "32\n",
      "2 : RowPatterns(NUMERIC(2-5) \\S() ALPHA(1-11) \\S() ALPHA(2-11) \\S() STREET(2-6) PUNC(|#) PUNC(#) NUMERIC(1-4))\n",
      "\n",
      "68\n",
      "1 : RowPatterns(NUMERIC(1-5) \\S() ALPHA(1-13) \\S() STREET(2-9) PUNC(|) SUD(3-5) \\S() NUMERIC(1-4))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We see the same patterns as with the longer process\n",
    "for cluster, pattern in patterns.items():\n",
    "    if cluster != -1:\n",
    "        print('{}'.format(pattern.top(1, pattern=True).freq))\n",
    "        print('{} : {}'.format(cluster, pattern))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate other data on a pattern\n",
    "To be able to evaluate patterns on other columns, we'll use a patternfinder object to help perform the same set and sequence of operations on the new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DIGIT(1-5), SPACE_REP(1-1), ALPHA(1-11), SPACE_REP(1-1), ALPHA(1-13), SPACE_REP(1-1), STREET(2-9), PUNCTUATION(1-1), SUD(2-9), SPACE_REP(1-1), DIGIT(1-5)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the top Pattern object from the 0th cluster. If pattern=False, a string would be returned instead\n",
    "# of a Pattern object\n",
    "pat = patterns[0].top(pattern=True)\n",
    "pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns True if match, else False\n",
    "test = '23 Nelson Jansen Ave|Apt 2'\n",
    "pat.compare(test, pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True, True, False]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we could also use the PatternFinder object to quickly compare a list of values with a pattern\n",
    "test = [\n",
    "    '832 SW VISTA AVENUE|APT 4',\n",
    "    '23 Nelson Jansen Ave|Apt 2',\n",
    "    '3 M J Ave|Fl 2',\n",
    "    '521 Avalon block |House 1'\n",
    "]\n",
    "pf.compare(pat, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
