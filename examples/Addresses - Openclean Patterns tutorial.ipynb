{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addresses Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goals for this notebook is to walk through all the steps in a pattern and mismatch detection process while performing the following tasks on a dataset containing data in an Address format:\n",
    "- Load / Sample data\n",
    "- Tokenize into encoded types\n",
    "    - Basic\n",
    "    - Advanced\n",
    "- Collect similar rows together\n",
    "- Align groups or clusters of similar rows\n",
    "- Generate Patterns for each group\n",
    "- Identify mismatches from the full dataset\n",
    "- PatternFinder Class Abstraction\n",
    "- Evaluate other address values on a pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "We're using a dataset with two addresse columns. Let's combine to get a full, more complicated column and drop any row with nulls. For the purposes of this example, we shall detect patterns from all distinct values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openclean.data.load import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>Address Continued</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8039</th>\n",
       "      <td>5305 RIVER RD NORTH</td>\n",
       "      <td>STE B</td>\n",
       "      <td>5305 RIVER RD NORTH|STE B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21067</th>\n",
       "      <td>5305 RIVER ROAD NORTH</td>\n",
       "      <td>SUITE B</td>\n",
       "      <td>5305 RIVER ROAD NORTH|SUITE B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16566</th>\n",
       "      <td>63722 ELLEN STREET</td>\n",
       "      <td>APT 1</td>\n",
       "      <td>63722 ELLEN STREET|APT 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20486</th>\n",
       "      <td>2390 EL CAMINO REAL</td>\n",
       "      <td>SUITE 210</td>\n",
       "      <td>2390 EL CAMINO REAL|SUITE 210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6458</th>\n",
       "      <td>247 S LOCUST ST</td>\n",
       "      <td>#247</td>\n",
       "      <td>247 S LOCUST ST|#247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Address  Address Continued                        Address\n",
       "8039     5305 RIVER RD NORTH             STE B      5305 RIVER RD NORTH|STE B\n",
       "21067  5305 RIVER ROAD NORTH           SUITE B  5305 RIVER ROAD NORTH|SUITE B\n",
       "16566     63722 ELLEN STREET             APT 1       63722 ELLEN STREET|APT 1\n",
       "20486    2390 EL CAMINO REAL         SUITE 210  2390 EL CAMINO REAL|SUITE 210\n",
       "6458         247 S LOCUST ST              #247           247 S LOCUST ST|#247"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Openclean abstracts over pandas dataframes\n",
    "address = dataset('../resources/dev/urban.csv', none_is='')\n",
    "address = address[['Address ', 'Address Continued']].dropna(how='any')\n",
    "address['Address'] = address['Address ']+ '|' + address['Address Continued']\n",
    "address.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2712, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are ~2700 values\n",
    "address.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "969"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with 969 unique addresses to detect dominant patterns from\n",
    "address_unique = address['Address'].unique()\n",
    "len(address_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize\n",
    "\n",
    "Splitting the values into basic and advanced types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean_pattern.tokenize.regex import DefaultTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('c',\n",
       " '/',\n",
       " 'o',\n",
       " ' ',\n",
       " 'pnc',\n",
       " ' ',\n",
       " 'real',\n",
       " ' ',\n",
       " 'estate',\n",
       " ' ',\n",
       " 'tax',\n",
       " ' ',\n",
       " 'credit',\n",
       " ' ',\n",
       " 'capital',\n",
       " '|',\n",
       " '121',\n",
       " ' ',\n",
       " 'sw',\n",
       " ' ',\n",
       " 'morrison',\n",
       " ' ',\n",
       " 'street',\n",
       " ' ',\n",
       " 'suite',\n",
       " ' ',\n",
       " '1300')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The default tokenizer shall split it on all punctuation, keeping '.'s intact if the \n",
    "# punctuation flag is set to true.\n",
    "\n",
    "dt = DefaultTokenizer()\n",
    "dt.tokenize(address_unique)[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Types\n",
    "With no type resolvers attached, the tokenizer shall convert each token to a supported basic datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(_'ALPHA'_(1,'c'),\n",
       " _'PUNC'_(1,'/'),\n",
       " _'ALPHA'_(1,'o'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(3,'pnc'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(4,'real'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(6,'estate'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(3,'tax'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(6,'credit'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(7,'capital'),\n",
       " _'PUNC'_(1,'|'),\n",
       " _'NUMERIC'_(3,'121'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(2,'sw'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(8,'morrison'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(6,'street'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(5,'suite'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'NUMERIC'_(4,'1300'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For use with the proceeding components, we convert the tokens into an internal Token representation\n",
    "encoded = dt.encode(address_unique)\n",
    "encoded[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_'NUMERIC'_(4,'1741')\n",
      "regex_type: SupportedDataTypes.ALPHA\n",
      "size: 1\n",
      "value: c\n",
      "rowidx: 8\n"
     ]
    }
   ],
   "source": [
    "# Each tuple in the list represents a row with each element inside the tuple, a Token Element. Each token element \n",
    "# maintains a bunch of profiling information which is later aggregated into patterns, anomalies, profiles etc.\n",
    "print(encoded[5][0])\n",
    "for v, item in vars(encoded[8][0]).items():\n",
    "    print('{}: {}'.format(v, item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced Types\n",
    "Here we attach an Address type resolver to a Tokenizer, which enables us to identify more complex tokens such as 'Street', 'Ave', 'Apt' etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean_pattern.datatypes.resolver import AddressDesignatorResolver, DefaultTypeResolver\n",
    "from openclean_pattern.tokenize.regex import RegexTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default type resolver identifies basic types, and adding an address resolver shall empower it use a \n",
    "# a repository of master data to identify specialized tokens by building a prefix tree\n",
    "\n",
    "tr = DefaultTypeResolver(interceptors=AddressDesignatorResolver())\n",
    "rt = RegexTokenizer(type_resolver=tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(_'ALPHA'_(1,'c'),\n",
       " _'PUNC'_(1,'/'),\n",
       " _'ALPHA'_(1,'o'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(3,'pnc'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(4,'real'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'STREET'_(6,'estate'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(3,'tax'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(6,'credit'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(7,'capital'),\n",
       " _'PUNC'_(1,'|'),\n",
       " _'NUMERIC'_(3,'121'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(2,'sw'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(8,'morrison'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'STREET'_(6,'street'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'SUD'_(5,'suite'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'NUMERIC'_(4,'1300'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We see now there exist internal representations for _STREET_ and a _SUD_ (secondary address designator) tokens\n",
    "address_encoded = rt.encode(address_unique)\n",
    "address_encoded[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect\n",
    "We aim to collect similar looking rows with each other using each token's regex_type and it's position as variables to calculate proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean_pattern.align.cluster import Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster uses a DBSCAN clusterer to calculate the distance between encoded rows and group them into clusters.\n",
    "# Here we use the tree-edit-distance to compute proximity\n",
    "clusters = Cluster(dist='TED', min_samples=10).collect(address_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "422\n",
      "1708                       1413 HAWTHORNE AVENUE|SPACE 23\n",
      "6095    MOTSCHENBACHER & BLATTNER LLP|117 SW TAYLOR ST...\n",
      "7932                          4201 NE 125TH PLACE|APT 173\n",
      "2495                               1843 SW 16TH AVE|APT 3\n",
      "3991                             843 ALDER CREEK DRIVE|#B\n",
      "Name: Address, dtype: object\n",
      "\n",
      "1\n",
      "15\n",
      "92      C/O PNC REAL ESTATE TAX CREDIT CAPITAL|121 SW ...\n",
      "2735                              1306 SE 36TH AVE|APT 11\n",
      "9492                   967 NE ORENCO STATION LOOP|APT 550\n",
      "4702                            3122 N WILLIAMS AVE|APT B\n",
      "1011                            5305 RIVER RD NORTH|STE B\n",
      "Name: Address, dtype: object\n",
      "\n",
      "2\n",
      "11\n",
      "7216    300 CARLSBAD VILLAGE DR|SUITE 108A-211\n",
      "4131                  3519 NE 15TH AVE|STE 424\n",
      "8045                   1837 SE ANKENY ST|APT B\n",
      "2351               10000 NE 7TH AVE|SUITE 330I\n",
      "607                    520 NW DAVIS ST|STE 215\n",
      "Name: Address, dtype: object\n",
      "\n",
      "3\n",
      "59\n",
      "8903           4207 SE WOODSTOCK BLVD|#419\n",
      "200            1926 W BURNSIDE ST|UNIT 317\n",
      "9492    967 NE ORENCO STATION LOOP|APT 550\n",
      "1230           3939 NE HANCOCK STREET|#308\n",
      "4582              545 NE THOMPSON ST|APT 2\n",
      "Name: Address, dtype: object\n",
      "\n",
      "4\n",
      "24\n",
      "5402                                236 SW MEADE ST|APT 4\n",
      "4670                            15642 NE GLISAN STREET|#1\n",
      "89      C/O PNC REAL ESTATE TAX CREDIT CAPITAL|121 SW ...\n",
      "6659                               400 E ROYAL LN|STE 290\n",
      "1674                            7885 SW VLAHOS DR|APT 106\n",
      "Name: Address, dtype: object\n",
      "\n",
      "5\n",
      "16\n",
      "3661    4417 NE KILLINGSWORTH STREET|UNIT 112\n",
      "6616                   2350 SW 257TH AVE|K104\n",
      "3353        1580 NE 32ND AVENUE|APARTMENT 415\n",
      "7967                5305 RIVER RD NORTH|STE B\n",
      "9402             6665 SW HAMPTON ST|SUITE 200\n",
      "Name: Address, dtype: object\n",
      "\n",
      "6\n",
      "67\n",
      "10222                       12250 SW PIONEER LN|349\n",
      "4782                            ONE AT&T WAY|2B112C\n",
      "7293     ECO FRIENDLY CLEANERS|11116 SW CAPITOL HWY\n",
      "2640                 4651 CHARLOTTE PARK DR|STE 300\n",
      "2701                     2600 CAPITOL AVE|SUITE 320\n",
      "Name: Address, dtype: object\n",
      "\n",
      "7\n",
      "31\n",
      "9189       199 SW SHEVLIN HIXON DRIVE|SUITE A\n",
      "4469               9230 NE ROCKSPRING ST|A430\n",
      "9806                5305 RIVER RD NORTH|STE B\n",
      "7265                 1015 NE 89TH AVE|APT 101\n",
      "8986    38100 SANDY HEIGHTS STREET|APT # L135\n",
      "Name: Address, dtype: object\n",
      "\n",
      "8\n",
      "10\n",
      "5346    320 E BUFFALO STREET|SUITE 500\n",
      "4196                  234 S MILL ST|#7\n",
      "1407           235 FRONT ST SE|STE 400\n",
      "2759    1 CHASE CORPORATE DR|SUITE 400\n",
      "7083        841 O'HARE PARKWAY|STE 100\n",
      "Name: Address, dtype: object\n",
      "\n",
      "9\n",
      "28\n",
      "8903              4207 SE WOODSTOCK BLVD|#419\n",
      "4325          11529 SW ZURICH STREET|UNIT 205\n",
      "2701               2600 CAPITOL AVE|SUITE 320\n",
      "249               1120 112TH AVE NE|SUITE 600\n",
      "3661    4417 NE KILLINGSWORTH STREET|UNIT 112\n",
      "Name: Address, dtype: object\n",
      "\n",
      "10\n",
      "10\n",
      "10220               8630 SW SCHOLLS FERRY RD|249\n",
      "6618     RILEY GOMBART|520 SW YAMHILL ST STE 600\n",
      "2642                      698 12TH ST SE|STE 200\n",
      "4338                   5305 RIVER RD NORTH|STE B\n",
      "1066                   5305 RIVER RD NORTH|STE B\n",
      "Name: Address, dtype: object\n",
      "\n",
      "11\n",
      "10\n",
      "1038     1915 NE STUCKI AVENUE|SUITE 308\n",
      "2065          PRAIRIE GROVE|104 ANGUS DR\n",
      "6388            1412 SW CUSTER DR|UNIT 4\n",
      "4789    1340 SOUTH SPECTRUM BLVD|STE 200\n",
      "952            5305 RIVER RD NORTH|STE B\n",
      "Name: Address, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We discover 11 different clusters with atleast 10 samples\n",
    "for cluster in clusters:\n",
    "    if cluster != -1:\n",
    "        print(cluster)\n",
    "        print(len(clusters[cluster]))\n",
    "        print(address.iloc[list(clusters[0])]['Address'].sample(5))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align\n",
    "Next, for the identified groups, we add Gap characters i.e. align them such that each row in the group has the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean_pattern.align.pad import Padder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(_'ALPHA'_(1,'c'),\n",
       " _'PUNC'_(1,'/'),\n",
       " _'ALPHA'_(1,'o'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(3,'pnc'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(4,'real'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'STREET'_(6,'estate'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(3,'tax'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(6,'credit'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(7,'capital'),\n",
       " _'PUNC'_(1,'|'),\n",
       " _'NUMERIC'_(3,'121'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(2,'sw'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'ALPHA'_(8,'morrison'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'STREET'_(6,'street'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'SUD'_(5,'suite'),\n",
       " _'\\\\S'_(1,' '),\n",
       " _'NUMERIC'_(4,'1300'),\n",
       " _'G'_(0,''))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The padder appends n gap Tokens to each row where n is the difference between the \n",
    "# longest row in the group and the current row\n",
    "pd = Padder()\n",
    "tokens = pd.align(address_encoded, clusters)\n",
    "tokens[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Patterns\n",
    "We analyse each cluster of aligned rows and generate an Openclean Pattern object. Pattern generation can either be row-wise, i.e. all rows with the same tokens are aggregated into one pattern, or column-wise, i.e. tokens at each position in rows are pooled to retrieve the most common token type per position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean_pattern.regex.compiler import DefaultRegexCompiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n",
      "0 : RowPatterns(NUMERIC(1-5) \\S() ALPHA(1-11) \\S() ALPHA(1-13) \\S() STREET(2-9) PUNC(|) SUD(2-9) \\S() NUMERIC(1-5))\n",
      "\n",
      "7\n",
      "1 : RowPatterns(ALPHA(1-14) \\S() ALPHA(1-9) \\S() ALPHA(1-14) \\S() ALPHA(2-9) PUNC(|) NUMERIC(1-4) \\S() sw(2-2) \\S() ALPHA(5-10) \\S() STREET(2-6) \\S() sXXXX(3-5) \\S() NUMERIC(1-4))\n",
      "\n",
      "1\n",
      "2 : RowPatterns(NUMERIC(3-4) \\S() ALPHA(1-5) \\S() ALPHA(3-7) \\S() STREET(3-7) PUNC(|) SUD(3-4) \\S() PUNC(#) NUMERIC(1-3))\n",
      "\n",
      "32\n",
      "3 : RowPatterns(NUMERIC(2-5) \\S() ALPHA(1-11) \\S() ALPHA(2-11) \\S() STREET(2-6) PUNC(|#) PUNC(#) NUMERIC(1-4))\n",
      "\n",
      "4\n",
      "4 : RowPatterns(NUMERIC(2-5) \\S() ALPHA(1-10) \\S() ALPHA(4-9) \\S() STREET(2-6) PUNC(|) ALPHA(1-7) \\S() ALPHA(1-5) \\S() NUMERIC(1-5))\n",
      "\n",
      "16\n",
      "5 : RowPatterns(NUMERIC(2-5) \\S() ALPHA(2-2) \\S() ALPHANUM(3-5) \\S() avX(2-3) PUNC(|) NUMERIC(1-5))\n",
      "\n",
      "67\n",
      "6 : RowPatterns(NUMERIC(1-5) \\S() ALPHA(1-13) \\S() STREET(2-9) PUNC(|) SUD(3-5) \\S() NUMERIC(1-4))\n",
      "\n",
      "11\n",
      "7 : RowPatterns(NUMERIC(3-5) \\S() ALPHA(1-9) \\S() ALPHA(3-10) \\S() STREET(2-7) \\S() STREET(2-7) PUNC(|) SUD(3-5) \\S() NUMERIC(1-3))\n",
      "\n",
      "10\n",
      "8 : RowPatterns(NUMERIC(3-5) \\S() ALPHA(1-2) \\S() ALPHA(4-13) \\S() STREET(2-3) PUNC(|) ALPHANUM(2-4))\n",
      "\n",
      "28\n",
      "9 : RowPatterns(NUMERIC(3-5) \\S() ALPHA(1-9) \\S() ALPHA(1-10) \\S() STREET(2-6) PUNC(|) NUMERIC(1-5))\n",
      "\n",
      "10\n",
      "10 : RowPatterns(NUMERIC(2-4) \\S() STREET(4-7) \\S() STREET(2-6) PUNC(|) SUD(3-5) \\S() NUMERIC(1-3))\n",
      "\n",
      "10\n",
      "11 : RowPatterns(NUMERIC(3-5) \\S() ALPHA(5-11) \\S() STREET(2-5) PUNC(|) NUMERIC(1-5))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the column method pools the majority token type from each token position across the rows. We discover\n",
    "# that 174 values of the 422 in the cluster 0 make a pattern, 32 of 59 make a pattern in cluster 3 and\n",
    "#  67 / 67 in cluster 6 follow the generated pattern\n",
    "\n",
    "rc = DefaultRegexCompiler(method='col', per_group='all')\n",
    "patterns = rc.compile(address_encoded, clusters)\n",
    "\n",
    "for cluster, pattern_group in patterns.items():\n",
    "    if cluster != -1:\n",
    "        print('{}'.format(pattern_group.top(1, pattern=True).freq))\n",
    "        print('{} : {}'.format(cluster, pattern_group))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Mismatches\n",
    "We identify mismatches in the column. i.e. values in each group/cluster that didn't match the selected patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Patterns\n",
      "[DIGIT(1-5), SPACE_REP(1-1), ALPHA(1-11), SPACE_REP(1-1), ALPHA(1-13), SPACE_REP(1-1), STREET(2-9), PUNCTUATION(1-1), SUD(2-9), SPACE_REP(1-1), DIGIT(1-5)]\n",
      "\n",
      "[DIGIT(1-5), SPACE_REP(1-1), ALPHA(1-14), SPACE_REP(1-1), ALPHA(1-12), SPACE_REP(1-1), ALPHA(1-14), SPACE_REP(1-1), ALPHA(1-11), SPACE_REP(1-1), ALPHA(1-12), SPACE_REP(1-1), ALPHA(1-8), SPACE_REP(1-1), ALPHA(1-12), SPACE_REP(1-1), STREET(2-6), SPACE_REP(1-1), SPACE_REP(1-1), SPACE_REP(1-1), DIGIT(3-4), SPACE_REP(1-1), DIGIT(1-4), SPACE_REP(1-1), SUD(5-5), SPACE_REP(1-1), DIGIT(4-4), DIGIT(3-3)]\n",
      "\n",
      "[ALPHA(1-14), SPACE_REP(1-1), ALPHA(1-9), SPACE_REP(1-1), ALPHA(1-14), SPACE_REP(1-1), ALPHA(2-9), PUNCTUATION(1-1), DIGIT(1-4), SPACE_REP(1-1), ALPHA(2-2), SPACE_REP(1-1), ALPHA(5-10), SPACE_REP(1-1), STREET(2-6), SPACE_REP(1-1), SUD(3-5), SPACE_REP(1-1), DIGIT(1-4)]\n",
      "\n",
      "[DIGIT(3-4), SPACE_REP(1-1), ALPHA(1-5), SPACE_REP(1-1), ALPHA(3-7), SPACE_REP(1-1), STREET(3-7), PUNCTUATION(1-1), SUD(3-4), SPACE_REP(1-1), PUNCTUATION(1-1), DIGIT(1-3)]\n",
      "\n",
      "[DIGIT(2-5), SPACE_REP(1-1), ALPHA(1-11), SPACE_REP(1-1), ALPHA(2-11), SPACE_REP(1-1), STREET(2-6), PUNCTUATION(1-1), PUNCTUATION(1-1), DIGIT(1-4)]\n",
      "\n",
      "[DIGIT(2-5), SPACE_REP(1-1), ALPHA(1-10), SPACE_REP(1-1), ALPHA(4-9), SPACE_REP(1-1), STREET(2-6), PUNCTUATION(1-1), ALPHA(1-7), SPACE_REP(1-1), ALPHA(1-5), SPACE_REP(1-1), DIGIT(1-5)]\n",
      "\n",
      "[DIGIT(2-5), SPACE_REP(1-1), ALPHA(2-2), SPACE_REP(1-1), ALPHANUM(3-5), SPACE_REP(1-1), STREET(2-3), PUNCTUATION(1-1), DIGIT(1-5)]\n",
      "\n",
      "[DIGIT(1-5), SPACE_REP(1-1), ALPHA(1-13), SPACE_REP(1-1), STREET(2-9), PUNCTUATION(1-1), SUD(3-5), SPACE_REP(1-1), DIGIT(1-4)]\n",
      "\n",
      "[DIGIT(3-5), SPACE_REP(1-1), ALPHA(1-9), SPACE_REP(1-1), ALPHA(3-10), SPACE_REP(1-1), STREET(2-7), SPACE_REP(1-1), STREET(2-7), PUNCTUATION(1-1), SUD(3-5), SPACE_REP(1-1), DIGIT(1-3)]\n",
      "\n",
      "[DIGIT(3-5), SPACE_REP(1-1), ALPHA(1-2), SPACE_REP(1-1), ALPHA(4-13), SPACE_REP(1-1), STREET(2-3), PUNCTUATION(1-1), ALPHANUM(2-4)]\n",
      "\n",
      "[DIGIT(3-5), SPACE_REP(1-1), ALPHA(1-9), SPACE_REP(1-1), ALPHA(1-10), SPACE_REP(1-1), STREET(2-6), PUNCTUATION(1-1), DIGIT(1-5)]\n",
      "\n",
      "[DIGIT(2-4), SPACE_REP(1-1), STREET(4-7), SPACE_REP(1-1), STREET(2-6), PUNCTUATION(1-1), SUD(3-5), SPACE_REP(1-1), DIGIT(1-3)]\n",
      "\n",
      "[DIGIT(3-5), SPACE_REP(1-1), ALPHA(5-11), SPACE_REP(1-1), STREET(2-5), PUNCTUATION(1-1), DIGIT(1-5)]\n",
      "\n",
      "------------------\n",
      "Mismatches: 599\n",
      "Sample:\n",
      "['5305 RIVER RD N|STE B'\n",
      " 'C/O PRAMEX INTERNATIONAL|1251 AVENUE OF THE AMERICAS, FL3'\n",
      " 'ATTENTION:  HEATHER J. HANSEN|591 SW MILL VIEW WAY'\n",
      " 'C/O DANICA HIBPSHMAN|888 SW FIFTH AVENUE SUITE 1600'\n",
      " '1600 PIONEER TOWER|888 SW FIFTH AVENUE']\n"
     ]
    }
   ],
   "source": [
    "# Let's select the top pattern in each cluster and filter out values that didn't match them. \n",
    "# Using the following patterns we discover 595 values that didn't match any pattern.\n",
    "\n",
    "print('Selected Patterns')\n",
    "selected_patterns = list()\n",
    "for pattern_group in patterns.values():\n",
    "    top = pattern_group.top(pattern=True)\n",
    "    selected_patterns.append(top)\n",
    "    print(top)\n",
    "    print()\n",
    "print('------------------')\n",
    "\n",
    "    \n",
    "mismatches = rc.mismatches(tokens, selected_patterns)\n",
    "print('Mismatches: {}'.format(len(address_unique[mismatches])))\n",
    "print('Sample:')\n",
    "print(address_unique[mismatches][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PattenFinder Abstraction\n",
    "A PatternFinder pipeline can be built with all the above components to easily detect patterns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean_pattern.opencleanpatternfinder import OpencleanPatternFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sequence of operations remains the same, i.e.: \n",
    "# sampling -> type resolution + tokenization -> collection -> alignment -> compilation\n",
    "\n",
    "pf = OpencleanPatternFinder(\n",
    "    distinct=True,\n",
    "    frac=1,\n",
    "    tokenizer=RegexTokenizer(\n",
    "        type_resolver=DefaultTypeResolver(\n",
    "            interceptors=AddressDesignatorResolver()\n",
    "        )\n",
    "    ),\n",
    "    collector=Cluster(dist='TED', min_samples=10),\n",
    "    aligner=Padder(),\n",
    "    compiler=DefaultRegexCompiler(method='col', per_group='all')\n",
    ")\n",
    "patterns = pf.find(address['Address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n",
      "0 : RowPatterns(NUMERIC(1-5) \\S() ALPHA(1-11) \\S() ALPHA(1-13) \\S() STREET(2-9) PUNC(|) SUD(2-9) \\S() NUMERIC(1-5))\n",
      "\n",
      "68\n",
      "1 : RowPatterns(NUMERIC(1-5) \\S() ALPHA(1-13) \\S() STREET(2-9) PUNC(|) SUD(3-5) \\S() NUMERIC(1-4))\n",
      "\n",
      "4\n",
      "2 : RowPatterns(NUMERIC(2-5) \\S() ALPHA(1-10) \\S() ALPHA(4-9) \\S() STREET(2-6) PUNC(|) ALPHA(1-7) \\S() ALPHA(1-5) \\S() NUMERIC(1-5))\n",
      "\n",
      "7\n",
      "3 : RowPatterns(ALPHA(1-14) \\S() ALPHA(1-9) \\S() ALPHA(1-14) \\S() ALPHA(2-9) PUNC(|) NUMERIC(1-4) \\S() sw(2-2) \\S() ALPHA(5-10) \\S() STREET(2-6) \\S() sXXXX(3-5) \\S() NUMERIC(1-4))\n",
      "\n",
      "32\n",
      "4 : RowPatterns(NUMERIC(2-5) \\S() ALPHA(1-11) \\S() ALPHA(2-11) \\S() STREET(2-6) PUNC(|#) PUNC(#) NUMERIC(1-4))\n",
      "\n",
      "28\n",
      "5 : RowPatterns(NUMERIC(3-5) \\S() ALPHA(1-9) \\S() ALPHA(1-10) \\S() STREET(2-6) PUNC(|) NUMERIC(1-5))\n",
      "\n",
      "10\n",
      "6 : RowPatterns(NUMERIC(3-5) \\S() ALPHA(1-2) \\S() ALPHA(4-13) \\S() STREET(2-3) PUNC(|) ALPHANUM(2-4))\n",
      "\n",
      "11\n",
      "7 : RowPatterns(NUMERIC(3-5) \\S() ALPHA(1-9) \\S() ALPHA(3-10) \\S() STREET(2-7) \\S() STREET(2-7) PUNC(|) SUD(3-5) \\S() NUMERIC(1-3))\n",
      "\n",
      "10\n",
      "8 : RowPatterns(NUMERIC(3-5) \\S() ALPHA(5-11) \\S() STREET(2-5) PUNC(|) NUMERIC(1-5))\n",
      "\n",
      "16\n",
      "9 : RowPatterns(NUMERIC(2-5) \\S() ALPHA(2-2) \\S() ALPHANUM(3-5) \\S() avX(2-3) PUNC(|) NUMERIC(1-5))\n",
      "\n",
      "10\n",
      "10 : RowPatterns(NUMERIC(2-4) \\S() STREET(4-7) \\S() STREET(2-6) PUNC(|) SUD(3-5) \\S() NUMERIC(1-3))\n",
      "\n",
      "5\n",
      "11 : RowPatterns(NUMERIC(3-4) \\S() ALPHA(1-5) \\S() ALPHANUM(3-4) \\S() STREET(3-7) PUNC(|) SUD(3-4) \\S() PUNC(#) NUMERIC(1-3))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We see the same patterns as without PatternFinder process\n",
    "for cluster, pattern in patterns.items():\n",
    "    if cluster != -1:\n",
    "        print('{}'.format(pattern.top(1, pattern=True).freq))\n",
    "        print('{} : {}'.format(cluster, pattern))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate other data on a pattern\n",
    "To be able to evaluate patterns on other columns, we'll use a patternfinder object to help perform the same set and sequence of operations on the new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DIGIT(1-5), SPACE_REP(1-1), ALPHA(1-11), SPACE_REP(1-1), ALPHA(1-13), SPACE_REP(1-1), STREET(2-9), PUNCTUATION(1-1), SUD(2-9), SPACE_REP(1-1), DIGIT(1-5)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the top Pattern object from the 0th cluster. If pattern=False, a string would be returned instead\n",
    "# of a Pattern object\n",
    "pat = patterns[0].top(pattern=True)\n",
    "pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns True if the value follows the pattern, else False. \n",
    "test = '23 Nelson Jansen Ave|Apt 2' # DIGIT SPACE ALPHA SPACE ALPHA SPACE STREET PUNC SUD SPACE DIGIT\n",
    "pat.compare(test, pf) #test has an extra pair of SPACE ALPHA than the pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True, True, False]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we could also use the PatternFinder object to quickly compare a list of values with a pattern. \n",
    "# We see rows 2 and 3 match the pattern\n",
    "test = [\n",
    "    '832 SW VISTA AVENUE|APT 4',\n",
    "    '23 Nelson Jansen Ave|Apt 2',\n",
    "    '3 M J Ave|Fl 2',\n",
    "    '521 Avalon block |House 1'\n",
    "]\n",
    "pf.compare(pat, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
