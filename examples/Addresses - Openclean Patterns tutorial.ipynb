{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addresses Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main goals for this notebook is to walk through all the steps in a pattern and mismatch detection process while performing the following tasks on a dataset containing data in an Address format:\n",
    "- Load / Sample data\n",
    "- Tokenize into encoded types\n",
    "    - Basic\n",
    "    - Advanced\n",
    "- Collect similar rows together\n",
    "- Align groups or clusters of similar rows\n",
    "- Generate Patterns for each group\n",
    "- Identify mismatches from the full dataset\n",
    "- PatternFinder Class Abstraction\n",
    "- Evaluate other address values on a pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "We're using a dataset with two addresse columns. Let's combine to get a full, more complicated column and drop any row with nulls. For the purposes of this example, we shall detect patterns from all distinct values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openclean.data.load import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address</th>\n",
       "      <th>Address Continued</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18794</th>\n",
       "      <td>ROBERT E KABACY</td>\n",
       "      <td>520 SW YAMHILL ST STE 600</td>\n",
       "      <td>ROBERT E KABACY|520 SW YAMHILL ST STE 600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11429</th>\n",
       "      <td>3181 NE 23RD ST</td>\n",
       "      <td>APT 1103</td>\n",
       "      <td>3181 NE 23RD ST|APT 1103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>2241 GREENSPRINGS DRIVE</td>\n",
       "      <td>UNIT 66</td>\n",
       "      <td>2241 GREENSPRINGS DRIVE|UNIT 66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18624</th>\n",
       "      <td>841 O'HARE PARKWAY</td>\n",
       "      <td>STE 100</td>\n",
       "      <td>841 O'HARE PARKWAY|STE 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30860</th>\n",
       "      <td>14708 SW BEARD RD</td>\n",
       "      <td>APT 225</td>\n",
       "      <td>14708 SW BEARD RD|APT 225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Address           Address Continued  \\\n",
       "18794          ROBERT E KABACY  520 SW YAMHILL ST STE 600   \n",
       "11429          3181 NE 23RD ST                   APT 1103   \n",
       "944    2241 GREENSPRINGS DRIVE                    UNIT 66   \n",
       "18624       841 O'HARE PARKWAY                    STE 100   \n",
       "30860        14708 SW BEARD RD                    APT 225   \n",
       "\n",
       "                                         Address  \n",
       "18794  ROBERT E KABACY|520 SW YAMHILL ST STE 600  \n",
       "11429                   3181 NE 23RD ST|APT 1103  \n",
       "944              2241 GREENSPRINGS DRIVE|UNIT 66  \n",
       "18624                 841 O'HARE PARKWAY|STE 100  \n",
       "30860                  14708 SW BEARD RD|APT 225  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Openclean abstracts over pandas dataframes\n",
    "address = dataset('data/urban.csv', none_is='')\n",
    "address = address[['Address ', 'Address Continued']].dropna(how='any')\n",
    "address['Address'] = address['Address ']+ '|' + address['Address Continued']\n",
    "address.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2712, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are ~2700 values\n",
    "address.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "969"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with 969 unique addresses to detect dominant patterns from\n",
    "address_unique = address['Address'].unique()\n",
    "len(address_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize\n",
    "\n",
    "Splitting the values into basic and advanced types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean_pattern.tokenize.regex import DefaultTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c',\n",
       " '/',\n",
       " 'o',\n",
       " ' ',\n",
       " 'pnc',\n",
       " ' ',\n",
       " 'real',\n",
       " ' ',\n",
       " 'estate',\n",
       " ' ',\n",
       " 'tax',\n",
       " ' ',\n",
       " 'credit',\n",
       " ' ',\n",
       " 'capital',\n",
       " '|',\n",
       " '121',\n",
       " ' ',\n",
       " 'sw',\n",
       " ' ',\n",
       " 'morrison',\n",
       " ' ',\n",
       " 'street',\n",
       " ' ',\n",
       " 'suite',\n",
       " ' ',\n",
       " '1300']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The default tokenizer shall split it on all punctuation, keeping '.'s intact if the \n",
    "# punctuation flag is set to true.\n",
    "\n",
    "dt = DefaultTokenizer()\n",
    "dt.encode(address_unique)[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Types\n",
    "With no type resolvers attached, the tokenizer shall convert each token to a supported basic datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c - ALPHA\n",
      "/ - PUNC\n",
      "o - ALPHA\n",
      "  - \\S\n",
      "pnc - ALPHA\n",
      "  - \\S\n",
      "real - ALPHA\n",
      "  - \\S\n",
      "estate - ALPHA\n",
      "  - \\S\n",
      "tax - ALPHA\n",
      "  - \\S\n",
      "credit - ALPHA\n",
      "  - \\S\n",
      "capital - ALPHA\n",
      "| - PUNC\n",
      "121 - NUMERIC\n",
      "  - \\S\n",
      "sw - ALPHA\n",
      "  - \\S\n",
      "morrison - ALPHA\n",
      "  - \\S\n",
      "street - ALPHA\n",
      "  - \\S\n",
      "suite - ALPHA\n",
      "  - \\S\n",
      "1300 - NUMERIC\n"
     ]
    }
   ],
   "source": [
    "# For use with the proceeding components, we convert the tokens into an internal Token representation\n",
    "encoded = dt.encode(address_unique)\n",
    "\n",
    "for i in range(len(encoded[8])):\n",
    "    print('{} - {}'.format(encoded[8][i],encoded[8][i].regex_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1741\n",
      "token_type: ALPHA\n",
      "rowidx: 8\n"
     ]
    }
   ],
   "source": [
    "# Each tuple in the list represents a row with each element inside the tuple, a Token Element. Each token element \n",
    "# maintains a bunch of profiling information which is later aggregated into patterns, anomalies, profiles etc.\n",
    "print(encoded[5][0])\n",
    "for v, item in vars(encoded[8][0]).items():\n",
    "    print('{}: {}'.format(v, item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced Types\n",
    "Here we attach an Address type resolver to a Tokenizer, which enables us to identify more complex tokens such as 'Street', 'Ave', 'Apt' etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean_pattern.datatypes.resolver import AddressDesignatorResolver, DefaultTypeResolver\n",
    "from openclean_pattern.tokenize.regex import RegexTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default type resolver identifies basic types, and adding an address resolver shall empower it use a \n",
    "# a repository of master data to identify specialized tokens by building a prefix tree\n",
    "\n",
    "tr = DefaultTypeResolver(interceptors=AddressDesignatorResolver())\n",
    "rt = RegexTokenizer(type_resolver=tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c - ALPHA\n",
      "/ - PUNC\n",
      "o - ALPHA\n",
      "  - \\S\n",
      "pnc - ALPHA\n",
      "  - \\S\n",
      "real - ALPHA\n",
      "  - \\S\n",
      "estate - STREET\n",
      "  - \\S\n",
      "tax - ALPHA\n",
      "  - \\S\n",
      "credit - ALPHA\n",
      "  - \\S\n",
      "capital - ALPHA\n",
      "| - PUNC\n",
      "121 - NUMERIC\n",
      "  - \\S\n",
      "sw - ALPHA\n",
      "  - \\S\n",
      "morrison - ALPHA\n",
      "  - \\S\n",
      "street - STREET\n",
      "  - \\S\n",
      "suite - SUD\n",
      "  - \\S\n",
      "1300 - NUMERIC\n"
     ]
    }
   ],
   "source": [
    "# We see now there exist internal representations for _STREET_ and a _SUD_ (secondary address designator) tokens\n",
    "address_encoded = rt.encode(address_unique)\n",
    "\n",
    "for i in range(len(address_encoded[8])):\n",
    "    print('{} - {}'.format(address_encoded[8][i],address_encoded[8][i].regex_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect\n",
    "We aim to collect similar looking rows with each other using each token's regex_type and it's position as variables to calculate proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean_pattern.collect.cluster import Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster uses a DBSCAN clusterer to calculate the distance between encoded rows and group them into clusters.\n",
    "# Here we use the tree-edit-distance to compute proximity\n",
    "clusters = Cluster(dist='TED', min_samples=10).collect(address_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "422\n",
      "4240               1416 SW 174TH AVE|APT 203\n",
      "2260    300 EXECUTIVE CENTER DRIVE|SUITE 201\n",
      "737           1277 TREAT BOULEVARD|SUITE 400\n",
      "1408                 235 FRONT ST SE|STE 400\n",
      "846         485 MASSACHUSETTS AVENUE|SUITE 3\n",
      "Name: Address, dtype: object\n",
      "\n",
      "1\n",
      "15\n",
      "10256    101 CRAWFORDS CORNER ROAD|STE 4-204R\n",
      "77                       1302 NE 3RD ST|STE 1\n",
      "9048            2050 GOODPASTURE LOOP|APT 141\n",
      "5503        1600 PIONEER TOWER|888 SW 5TH AVE\n",
      "9145                1300 22ND STREET|UNIT 503\n",
      "Name: Address, dtype: object\n",
      "\n",
      "2\n",
      "11\n",
      "9187    199 SW SHEVLIN HIXON DRIVE|SUITE A\n",
      "200            1926 W BURNSIDE ST|UNIT 317\n",
      "4328       11529 SW ZURICH STREET|UNIT 205\n",
      "3802      3340 NE M L KING JR BLVD|APT 407\n",
      "1408               235 FRONT ST SE|STE 400\n",
      "Name: Address, dtype: object\n",
      "\n",
      "3\n",
      "59\n",
      "6454    4137 SE CESAR E CHAVEZ BLVD|APT 16\n",
      "2571            550 CALIFORNIA AVE|STE 200\n",
      "4413               5305 RIVER RD N|SUITE B\n",
      "9721                  109 SE ALDER ST|#710\n",
      "1674             7885 SW VLAHOS DR|APT 106\n",
      "Name: Address, dtype: object\n",
      "\n",
      "4\n",
      "24\n",
      "618                  1980 WILLAMETTE FALLS DRIVE|#120-313\n",
      "5483    C/O APERION MANAGEMENT GROUP LLC|20310 EMPIRE ...\n",
      "7880                             698 12TH ST SE|SUITE 200\n",
      "7215                        320 SW CENTURY DR|STE 405-240\n",
      "1036                      1915 NE STUCKI AVENUE|SUITE 308\n",
      "Name: Address, dtype: object\n",
      "\n",
      "5\n",
      "16\n",
      "9189     199 SW SHEVLIN HIXON DRIVE|SUITE A\n",
      "10069                1284 N 19TH ST|UNIT 98\n",
      "5578          1111 N ROOSEVELT DR|SUITE 350\n",
      "6150     C/O CARA COTTER|130 CORPORATE BLVD\n",
      "952               5305 RIVER RD NORTH|STE B\n",
      "Name: Address, dtype: object\n",
      "\n",
      "6\n",
      "67\n",
      "2334            8952 N FORTUNE AVE|A\n",
      "6456            247 S LOCUST ST|#247\n",
      "2197    12270 SW GINGHAM LANE|UNIT D\n",
      "8909          716 SE 34 AVENUE|APT 2\n",
      "607          520 NW DAVIS ST|STE 215\n",
      "Name: Address, dtype: object\n",
      "\n",
      "7\n",
      "31\n",
      "947            528 WEST 10TH AVENUE|APT 1\n",
      "7209       888 SW FIFTH AVENUE|SUITE 1600\n",
      "5254          20 S THIRD STREET|SUITE 210\n",
      "8634             33470 SW CHINOOK PLZ|213\n",
      "5505    1600 PIONEER TOWER|888 SW 5TH AVE\n",
      "Name: Address, dtype: object\n",
      "\n",
      "8\n",
      "10\n",
      "1372    9020 SW WASHINGTON SQUARE RD|STE 570\n",
      "4891            18423 NW CHEMEKETA LN|UNIT B\n",
      "5402                   236 SW MEADE ST|APT 4\n",
      "5268                   4391 SW 76TH AVE|#228\n",
      "5560               5305 RIVER RD NORTH|STE B\n",
      "Name: Address, dtype: object\n",
      "\n",
      "9\n",
      "28\n",
      "1709    1413 HAWTHORNE AVE|SPACE 23\n",
      "8298      5305 RIVER RD NORTH|STE B\n",
      "6748      5305 RIVER RD NORTH|STE B\n",
      "7999      5305 RIVER RD NORTH|STE B\n",
      "7081     841 O'HARE PARKWAY|STE 100\n",
      "Name: Address, dtype: object\n",
      "\n",
      "10\n",
      "10\n",
      "5611    780 COMMERCIAL ST SE|SUITE 100\n",
      "5579     1111 N ROOSEVELT DR|SUITE 350\n",
      "725              5305 RIVER RD N|STE B\n",
      "6659            400 E ROYAL LN|STE 290\n",
      "4606         5305 RIVER RD NORTH|STE B\n",
      "Name: Address, dtype: object\n",
      "\n",
      "11\n",
      "10\n",
      "8270       528 WEST 10TH AVENUE|APT #1\n",
      "5021         18750 WILLAMETTE DR|STE F\n",
      "5402             236 SW MEADE ST|APT 4\n",
      "3488            2516 SE HARRISON ST|61\n",
      "2640    4651 CHARLOTTE PARK DR|STE 300\n",
      "Name: Address, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We discover 11 different clusters with atleast 10 samples\n",
    "for cluster in clusters:\n",
    "    if cluster != -1:\n",
    "        print(cluster)\n",
    "        print(len(clusters[cluster]))\n",
    "        print(address.iloc[list(clusters[0])]['Address'].sample(5))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align\n",
    "Next, for the identified groups, we add Gap characters i.e. align them such that each row in the group has the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean_pattern.align.pad import Padder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('c',\n",
       " '/',\n",
       " 'o',\n",
       " ' ',\n",
       " 'pnc',\n",
       " ' ',\n",
       " 'real',\n",
       " ' ',\n",
       " 'estate',\n",
       " ' ',\n",
       " 'tax',\n",
       " ' ',\n",
       " 'credit',\n",
       " ' ',\n",
       " 'capital',\n",
       " '|',\n",
       " '121',\n",
       " ' ',\n",
       " 'sw',\n",
       " ' ',\n",
       " 'morrison',\n",
       " ' ',\n",
       " 'street',\n",
       " ' ',\n",
       " 'suite',\n",
       " ' ',\n",
       " '1300',\n",
       " '')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The padder appends n gap Tokens to each row where n is the difference between the \n",
    "# longest row in the group and the current row\n",
    "pd = Padder()\n",
    "tokens = pd.align(address_encoded, clusters)\n",
    "tokens[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Patterns\n",
    "We analyse each cluster of aligned rows and generate an Openclean Pattern object. Pattern generation can either be row-wise, i.e. all rows with the same tokens are aggregated into one pattern, or column-wise, i.e. tokens at each position in rows are pooled to retrieve the most common token type per position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean_pattern.regex.compiler import DefaultRegexCompiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174\n",
      "0 : RowPatterns(NUMERIC(1-5) \\S() ALPHA(1-11) \\S() ALPHA(1-13) \\S() STREET(2-9) PUNC(|) SUD(2-9) \\S() NUMERIC(1-5))\n",
      "\n",
      "7\n",
      "1 : RowPatterns(ALPHA(1-14) \\S() ALPHA(1-9) \\S() ALPHA(1-14) \\S() ALPHA(2-9) PUNC(|) NUMERIC(1-4) \\S() sw(2-2) \\S() ALPHA(5-10) \\S() STREET(2-6) \\S() sXXXX(3-5) \\S() NUMERIC(1-4))\n",
      "\n",
      "1\n",
      "2 : RowPatterns(NUMERIC(3-4) \\S() ALPHA(1-5) \\S() ALPHA(3-7) \\S() STREET(3-7) PUNC(|) SUD(3-4) \\S() PUNC(#) NUMERIC(1-3))\n",
      "\n",
      "32\n",
      "3 : RowPatterns(NUMERIC(2-5) \\S() ALPHA(1-11) \\S() ALPHA(2-11) \\S() STREET(2-6) PUNC(#|) PUNC(#) NUMERIC(1-4))\n",
      "\n",
      "4\n",
      "4 : RowPatterns(NUMERIC(2-5) \\S() ALPHA(1-10) \\S() ALPHA(4-9) \\S() STREET(2-6) PUNC(|) ALPHA(1-7) \\S() ALPHA(1-5) \\S() NUMERIC(1-5))\n",
      "\n",
      "16\n",
      "5 : RowPatterns(NUMERIC(2-5) \\S() ALPHA(2-2) \\S() ALPHANUM(3-5) \\S() avX(2-3) PUNC(|) NUMERIC(1-5))\n",
      "\n",
      "67\n",
      "6 : RowPatterns(NUMERIC(1-5) \\S() ALPHA(1-13) \\S() STREET(2-9) PUNC(|) SUD(3-5) \\S() NUMERIC(1-4))\n",
      "\n",
      "11\n",
      "7 : RowPatterns(NUMERIC(3-5) \\S() ALPHA(1-9) \\S() ALPHA(3-10) \\S() STREET(2-7) \\S() STREET(2-7) PUNC(|) SUD(3-5) \\S() NUMERIC(1-3))\n",
      "\n",
      "10\n",
      "8 : RowPatterns(NUMERIC(3-5) \\S() ALPHA(1-2) \\S() ALPHA(4-13) \\S() STREET(2-3) PUNC(|) ALPHANUM(2-4))\n",
      "\n",
      "28\n",
      "9 : RowPatterns(NUMERIC(3-5) \\S() ALPHA(1-9) \\S() ALPHA(1-10) \\S() STREET(2-6) PUNC(|) NUMERIC(1-5))\n",
      "\n",
      "10\n",
      "10 : RowPatterns(NUMERIC(2-4) \\S() STREET(4-7) \\S() STREET(2-6) PUNC(|) SUD(3-5) \\S() NUMERIC(1-3))\n",
      "\n",
      "10\n",
      "11 : RowPatterns(NUMERIC(3-5) \\S() ALPHA(5-11) \\S() STREET(2-5) PUNC(|) NUMERIC(1-5))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the column method pools the majority token type from each token position across the rows. We discover\n",
    "# that 174 values of the 422 in the cluster 0 make a pattern, 32 of 59 make a pattern in cluster 3 and\n",
    "#  67 / 67 in cluster 6 follow the generated pattern\n",
    "\n",
    "rc = DefaultRegexCompiler(method='col', per_group='all')\n",
    "patterns = rc.compile(address_encoded, clusters)\n",
    "\n",
    "for cluster, pattern_group in patterns.items():\n",
    "    if cluster != -1:\n",
    "        print('{}'.format(pattern_group.top(1, pattern=True).freq))\n",
    "        print('{} : {}'.format(cluster, pattern_group))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify Mismatches\n",
    "We identify mismatches in the column. i.e. values in each group/cluster that didn't match the selected patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Patterns\n",
      "[NUMERIC(1-5), \\S(1-1), ALPHA(1-11), \\S(1-1), ALPHA(1-13), \\S(1-1), STREET(2-9), PUNC(1-1), SUD(2-9), \\S(1-1), NUMERIC(1-5)]\n",
      "\n",
      "[NUMERIC(1-5), \\S(1-1), ALPHA(1-14), \\S(1-1), ALPHA(1-12), \\S(1-1), ALPHA(1-14), \\S(1-1), ALPHA(1-11), \\S(1-1), ALPHA(1-12), \\S(1-1), ALPHA(1-8), \\S(1-1), ALPHA(1-12), \\S(1-1), STREET(2-6), \\S(1-1), \\S(1-1), \\S(1-1), NUMERIC(3-4), \\S(1-1), NUMERIC(1-4), \\S(1-1), SUD(5-5), \\S(1-1), NUMERIC(4-4), NUMERIC(3-3)]\n",
      "\n",
      "[ALPHA(1-14), \\S(1-1), ALPHA(1-9), \\S(1-1), ALPHA(1-14), \\S(1-1), ALPHA(2-9), PUNC(1-1), NUMERIC(1-4), \\S(1-1), ALPHA(2-2), \\S(1-1), ALPHA(5-10), \\S(1-1), STREET(2-6), \\S(1-1), SUD(3-5), \\S(1-1), NUMERIC(1-4)]\n",
      "\n",
      "[NUMERIC(3-4), \\S(1-1), ALPHA(1-5), \\S(1-1), ALPHA(3-7), \\S(1-1), STREET(3-7), PUNC(1-1), SUD(3-4), \\S(1-1), PUNC(1-1), NUMERIC(1-3)]\n",
      "\n",
      "[NUMERIC(2-5), \\S(1-1), ALPHA(1-11), \\S(1-1), ALPHA(2-11), \\S(1-1), STREET(2-6), PUNC(1-1), PUNC(1-1), NUMERIC(1-4)]\n",
      "\n",
      "[NUMERIC(2-5), \\S(1-1), ALPHA(1-10), \\S(1-1), ALPHA(4-9), \\S(1-1), STREET(2-6), PUNC(1-1), ALPHA(1-7), \\S(1-1), ALPHA(1-5), \\S(1-1), NUMERIC(1-5)]\n",
      "\n",
      "[NUMERIC(2-5), \\S(1-1), ALPHA(2-2), \\S(1-1), ALPHANUM(3-5), \\S(1-1), STREET(2-3), PUNC(1-1), NUMERIC(1-5)]\n",
      "\n",
      "[NUMERIC(1-5), \\S(1-1), ALPHA(1-13), \\S(1-1), STREET(2-9), PUNC(1-1), SUD(3-5), \\S(1-1), NUMERIC(1-4)]\n",
      "\n",
      "[NUMERIC(3-5), \\S(1-1), ALPHA(1-9), \\S(1-1), ALPHA(3-10), \\S(1-1), STREET(2-7), \\S(1-1), STREET(2-7), PUNC(1-1), SUD(3-5), \\S(1-1), NUMERIC(1-3)]\n",
      "\n",
      "[NUMERIC(3-5), \\S(1-1), ALPHA(1-2), \\S(1-1), ALPHA(4-13), \\S(1-1), STREET(2-3), PUNC(1-1), ALPHANUM(2-4)]\n",
      "\n",
      "[NUMERIC(3-5), \\S(1-1), ALPHA(1-9), \\S(1-1), ALPHA(1-10), \\S(1-1), STREET(2-6), PUNC(1-1), NUMERIC(1-5)]\n",
      "\n",
      "[NUMERIC(2-4), \\S(1-1), STREET(4-7), \\S(1-1), STREET(2-6), PUNC(1-1), SUD(3-5), \\S(1-1), NUMERIC(1-3)]\n",
      "\n",
      "[NUMERIC(3-5), \\S(1-1), ALPHA(5-11), \\S(1-1), STREET(2-5), PUNC(1-1), NUMERIC(1-5)]\n",
      "\n",
      "------------------\n",
      "Mismatches: 599\n",
      "Sample:\n",
      "['5305 RIVER RD N|STE B'\n",
      " 'C/O PRAMEX INTERNATIONAL|1251 AVENUE OF THE AMERICAS, FL3'\n",
      " 'ATTENTION:  HEATHER J. HANSEN|591 SW MILL VIEW WAY'\n",
      " 'C/O DANICA HIBPSHMAN|888 SW FIFTH AVENUE SUITE 1600'\n",
      " '1600 PIONEER TOWER|888 SW FIFTH AVENUE']\n"
     ]
    }
   ],
   "source": [
    "# Let's select the top pattern in each cluster and filter out values that didn't match them. \n",
    "# Using the following patterns we discover 595 values that didn't match any pattern.\n",
    "\n",
    "print('Selected Patterns')\n",
    "selected_patterns = list()\n",
    "for pattern_group in patterns.values():\n",
    "    top = pattern_group.top(pattern=True)\n",
    "    selected_patterns.append(top)\n",
    "    print(top)\n",
    "    print()\n",
    "print('------------------')\n",
    "\n",
    "    \n",
    "mismatches = rc.mismatches(tokens, selected_patterns)\n",
    "print('Mismatches: {}'.format(len(address_unique[mismatches])))\n",
    "print('Sample:')\n",
    "print(address_unique[mismatches][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PattenFinder Abstraction\n",
    "A PatternFinder pipeline can be built with all the above components to easily detect patterns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean_pattern.opencleanpatternfinder import OpencleanPatternFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sequence of operations remains the same, i.e.: \n",
    "# sampling -> type resolution + tokenization -> collection -> alignment -> compilation\n",
    "\n",
    "pf = OpencleanPatternFinder(\n",
    "    distinct=True,\n",
    "    frac=1,\n",
    "    tokenizer=RegexTokenizer(\n",
    "        type_resolver=DefaultTypeResolver(\n",
    "            interceptors=AddressDesignatorResolver()\n",
    "        )\n",
    "    ),\n",
    "    collector=Cluster(dist='TED', min_samples=10),\n",
    "    aligner=Padder(),\n",
    "    compiler=DefaultRegexCompiler(method='col', per_group='all')\n",
    ")\n",
    "patterns = pf.find(address['Address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "0 : RowPatterns(NUMERIC(2-5) \\S() ALPHA(1-11) \\S() ALPHA(2-11) \\S() STREET(2-6) PUNC(#|) PUNC(#) NUMERIC(1-4))\n",
      "\n",
      "16\n",
      "1 : RowPatterns(NUMERIC(2-5) \\S() ALPHA(2-2) \\S() ALPHANUM(3-5) \\S() avX(2-3) PUNC(|) NUMERIC(1-5))\n",
      "\n",
      "174\n",
      "2 : RowPatterns(NUMERIC(1-5) \\S() ALPHA(1-11) \\S() ALPHA(1-13) \\S() STREET(2-9) PUNC(|) SUD(2-9) \\S() NUMERIC(1-5))\n",
      "\n",
      "10\n",
      "3 : RowPatterns(NUMERIC(2-4) \\S() STREET(4-7) \\S() STREET(2-6) PUNC(|) SUD(3-5) \\S() NUMERIC(1-3))\n",
      "\n",
      "4\n",
      "4 : RowPatterns(NUMERIC(2-5) \\S() ALPHA(1-10) \\S() ALPHA(4-9) \\S() STREET(2-6) PUNC(|) ALPHA(1-7) \\S() ALPHA(1-5) \\S() NUMERIC(1-5))\n",
      "\n",
      "11\n",
      "5 : RowPatterns(NUMERIC(3-5) \\S() ALPHA(1-9) \\S() ALPHA(3-10) \\S() STREET(2-7) \\S() STREET(2-7) PUNC(|) SUD(3-5) \\S() NUMERIC(1-3))\n",
      "\n",
      "7\n",
      "6 : RowPatterns(ALPHA(1-14) \\S() ALPHA(1-9) \\S() ALPHA(1-14) \\S() ALPHA(2-9) PUNC(|) NUMERIC(1-4) \\S() sw(2-2) \\S() ALPHA(5-10) \\S() STREET(2-6) \\S() sXXXX(3-5) \\S() NUMERIC(1-4))\n",
      "\n",
      "28\n",
      "7 : RowPatterns(NUMERIC(3-5) \\S() ALPHA(1-9) \\S() ALPHA(1-10) \\S() STREET(2-6) PUNC(|) NUMERIC(1-5))\n",
      "\n",
      "68\n",
      "8 : RowPatterns(NUMERIC(1-5) \\S() ALPHA(1-13) \\S() STREET(2-9) PUNC(|) SUD(3-5) \\S() NUMERIC(1-4))\n",
      "\n",
      "10\n",
      "9 : RowPatterns(NUMERIC(3-5) \\S() ALPHA(1-2) \\S() ALPHA(4-13) \\S() STREET(2-3) PUNC(|) ALPHANUM(2-4))\n",
      "\n",
      "1\n",
      "11 : RowPatterns(NUMERIC(3-4) \\S() ALPHA(1-5) \\S() ALPHA(3-7) \\S() STREET(3-7) PUNC(|) SUD(3-4) \\S() PUNC(#) NUMERIC(1-3))\n",
      "\n",
      "10\n",
      "10 : RowPatterns(NUMERIC(3-5) \\S() ALPHA(5-11) \\S() STREET(2-5) PUNC(|) NUMERIC(1-5))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We see the same patterns as without PatternFinder process\n",
    "for cluster, pattern in patterns.items():\n",
    "    if cluster != -1:\n",
    "        print('{}'.format(pattern.top(1, pattern=True).freq))\n",
    "        print('{} : {}'.format(cluster, pattern))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate other data on a pattern\n",
    "To be able to evaluate patterns on other columns, we'll use a patternfinder object to help perform the same set and sequence of operations on the new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NUMERIC(1-5), \\S(1-1), ALPHA(1-11), \\S(1-1), ALPHA(1-13), \\S(1-1), STREET(2-9), PUNC(1-1), SUD(2-9), \\S(1-1), NUMERIC(1-5)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As an example, get the top Pattern object from the 2nd cluster. If pattern=False, a string would be returned instead\n",
    "# of a Pattern object. The pattern looks like:\n",
    "# [NUMERIC(1-5), \\S(1-1), ALPHA(1-11), \\S(1-1), ALPHA(1-13), \\S(1-1), STREET(2-9), PUNC(1-1), SUD(2-9), \\S(1-1), NUMERIC(1-5)]\n",
    "\n",
    "# Note: while re-running the notebook, this pattern might be part of a different cluster in the previous cell.\n",
    "# this is because the indeterminate nature of dbscan clustering at the collect stage\n",
    "\n",
    "pat = patterns[2].top(pattern=True)\n",
    "pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns True if the value follows the pattern, else False. \n",
    "test = '23 Nelson Jansen Ave|Apt 2' # DIGIT SPACE ALPHA SPACE ALPHA SPACE STREET PUNC SUD SPACE DIGIT\n",
    "pat.compare(test, pf.tokenizer) #test has an extra pair of SPACE ALPHA than the pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True, True, False]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we could also use the PatternFinder object to quickly compare a list of values with a pattern. \n",
    "# We see rows 2 and 3 match the pattern\n",
    "test = [\n",
    "    '832 SW VISTA AVENUE|APT 4', # vista is a street identifier (https://pe.usps.com/text/pub28/28apc_002.htm)\n",
    "    '23 Nelson Jansen Ave|Apt 2',\n",
    "    '3 M J Ave|Fl 2',\n",
    "    '521 Avalon block |House 1' # extra space before |\n",
    "]\n",
    "pf.compare(pat, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (openclean-core)",
   "language": "python",
   "name": "pycharm-c6d12a8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
