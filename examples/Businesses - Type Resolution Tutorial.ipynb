{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Businesses  - Type Resolution Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we analyze various columns in a business registrations dataset and look at various ways to detect inconsistencies in the data using the column pattern.\n",
    "\n",
    "Goals:\n",
    "- Pattern generation with type resolvers\n",
    "- Basic anomaly detection\n",
    "- Non-basic/advanced anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Business Name</th>\n",
       "      <th>Entity Type</th>\n",
       "      <th>Registry Date</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>Zip Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9495</th>\n",
       "      <td>CHIEF AUTO SPORTS LLC</td>\n",
       "      <td>DOMESTIC LIMITED LIABILITY COMPANY</td>\n",
       "      <td>07/27/2020</td>\n",
       "      <td>940 WILLAMETTE ST STE 400</td>\n",
       "      <td>EUGENE</td>\n",
       "      <td>97401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10682</th>\n",
       "      <td>UAS AERIAL SOLUTIONS LLC</td>\n",
       "      <td>DOMESTIC LIMITED LIABILITY COMPANY</td>\n",
       "      <td>07/30/2020</td>\n",
       "      <td>5823 NW VILLAGE GREEN PL</td>\n",
       "      <td>CORVALLIS</td>\n",
       "      <td>97330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>FLYING CLIPPER</td>\n",
       "      <td>ASSUMED BUSINESS NAME</td>\n",
       "      <td>07/29/2020</td>\n",
       "      <td>497 OAKWAY RD</td>\n",
       "      <td>EUGENE</td>\n",
       "      <td>97401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6700</th>\n",
       "      <td>GLOW BEAUTY LOUNGE</td>\n",
       "      <td>ASSUMED BUSINESS NAME</td>\n",
       "      <td>07/20/2020</td>\n",
       "      <td>1820 COMMERCIAL ST SE</td>\n",
       "      <td>SALEM</td>\n",
       "      <td>97302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4752</th>\n",
       "      <td>ROGUE ARTIST SUPPORT SERVICES LLC</td>\n",
       "      <td>DOMESTIC LIMITED LIABILITY COMPANY</td>\n",
       "      <td>07/14/2020</td>\n",
       "      <td>4850 S PACIFIC HWY</td>\n",
       "      <td>PHOENIX</td>\n",
       "      <td>97535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Business Name                         Entity Type  \\\n",
       "9495               CHIEF AUTO SPORTS LLC  DOMESTIC LIMITED LIABILITY COMPANY   \n",
       "10682           UAS AERIAL SOLUTIONS LLC  DOMESTIC LIMITED LIABILITY COMPANY   \n",
       "9993                      FLYING CLIPPER               ASSUMED BUSINESS NAME   \n",
       "6700                  GLOW BEAUTY LOUNGE               ASSUMED BUSINESS NAME   \n",
       "4752   ROGUE ARTIST SUPPORT SERVICES LLC  DOMESTIC LIMITED LIABILITY COMPANY   \n",
       "\n",
       "      Registry Date                   Address        City Zip Code  \n",
       "9495     07/27/2020  940 WILLAMETTE ST STE 400     EUGENE    97401  \n",
       "10682    07/30/2020   5823 NW VILLAGE GREEN PL  CORVALLIS    97330  \n",
       "9993     07/29/2020              497 OAKWAY RD     EUGENE    97401  \n",
       "6700     07/20/2020      1820 COMMERCIAL ST SE      SALEM    97302  \n",
       "4752     07/14/2020         4850 S PACIFIC HWY    PHOENIX    97535  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "# The dataset has registration information for many businesses in the US including names, \n",
    "# entity information, dates, ownership information, and address\n",
    "\n",
    "df = pd.read_csv('../resources/dev/urban.csv', usecols=['Business Name','Entity Type','Registry Date','Address ', 'City', 'Zip Code']).drop_duplicates().reset_index(drop=True)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11501, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pattern Generation with Type Resolution\n",
    "We use a patternfinder object to identify patterns in the data, using the internal business entity type resolver to help distinguish between business registration suffix tokens.\n",
    "\n",
    "The tokenizer accepts a type resolver object to allow prefix matching as part of the tokenization. Internally, each type resolver is built on a master vocabulary with prefix searches optimized using a prefix tree. The type resolver base class is easily implementable and makes pattern detection with custom nonbasic types extremely flexible and powerful.\n",
    "\n",
    "The DefaultTypeResolver allows for the Basic types (Alpha, Alphanum, Digit, Punctuations, Spaces, Gaps) to be detected, whereas more advanced inbuilt implementations allow for detection of Business Entities (through their suffixes), Addresses (using USPS primary and secondary unit designator terms e.g. Street, Ave, Apt etc), Dates (Month and Weekday), and GeoSpatial Entities (using nyu datamart-geo as the base master data). Ofcourse, as mentioned earlier, the type resolver class can be extended to cater for one's needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the patternfinder to quickly understand column patterns\n",
    "from openclean_pattern.opencleanpatternfinder import OpencleanPatternFinder as PatternFinder\n",
    "from openclean_pattern.datatypes.resolver import BusinessEntityResolver, DefaultTypeResolver\n",
    "from openclean_pattern.tokenize.regex import RegexTokenizer\n",
    "from openclean_pattern.align.cluster import Cluster\n",
    "from openclean_pattern.align.pad import Padder\n",
    "from openclean_pattern.regex.compiler import DefaultRegexCompiler\n",
    "\n",
    "# create a new DefaultTypeResolver object (identifies basic types)\n",
    "# intercepted by a BusinessEntityResolver (identifies company suffixes)\n",
    "# plug these into a new RegexTokenizer that'll tokenize the remaining values not identified by the type resolvers\n",
    "# on all delimiters except dots(.) because they're abbreviation characters\n",
    "\n",
    "rt = RegexTokenizer(\n",
    "        abbreviations=True,\n",
    "        type_resolver=DefaultTypeResolver(\n",
    "            interceptors=BusinessEntityResolver()\n",
    "        )\n",
    "    )\n",
    "column = 'Business Name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new PatternFinder object with the Cluster collector\n",
    "\n",
    "pf = PatternFinder(distinct=True,\n",
    "                    tokenizer=rt,\n",
    "                    collector=Cluster(dist=\"TED\", min_samples=100),\n",
    "                    aligner=Padder(),\n",
    "                    compiler=DefaultRegexCompiler(method='col', per_group='all')\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find patterns\n",
    "grouped_patterns = pf.find(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1174\n",
      "0 ALPHA(1-14) \\S() ALPHA(1-14) \\S() BUSINESS(2-25)\n",
      "\n",
      "641\n",
      "1 ALPHA(1-13) \\S() ALPHA(1-14)\n",
      "\n",
      "904\n",
      "2 ALPHA(1-12) \\S() ALPHA(1-13) \\S() ALPHA(1-14) \\S() BUSINESS(2-25)\n",
      "\n",
      "370\n",
      "3 ALPHA(2-21) \\S() BUSINESS(2-25)\n",
      "\n",
      "111\n",
      "4 ALPHA(1-11) \\S() ALPHA(1-13) \\S() ALPHA(1-14) \\S() ALPHA(1-12) PUNC(,) \\S() BUSINESS(2-12)\n",
      "\n",
      "394\n",
      "5 ALPHA(1-11) \\S() ALPHA(1-14) \\S() ALPHA(1-14) PUNC(,!) \\S() BUSINESS(2-9)\n",
      "\n",
      "673\n",
      "6 ALPHA(1-14) \\S() ALPHA(1-13) \\S() ALPHA(1-14)\n",
      "\n",
      "469\n",
      "7 ALPHA(1-14) \\S() ALPHA(1-15) PUNC(,!) \\S() BUSINESS(2-4)\n",
      "\n",
      "235\n",
      "8 ALPHA(1-12) \\S() ALPHA(1-13) \\S() ALPHA(1-12) \\S() ALPHA(1-14)\n",
      "\n",
      "168\n",
      "9 ALPHA(1-21)\n",
      "\n",
      "132\n",
      "10 ALPHA(3-18) PUNC(,) \\S() BUSINESS(3-4)\n",
      "\n",
      "256\n",
      "11 ALPHA(1-11) \\S() ALPHA(1-14) \\S() ALPHA(1-12) \\S() ALPHA(1-14) \\S() BUSINESS(2-25)\n",
      "\n",
      "69\n",
      "12 ALPHA(1-11) \\S() ALPHA(1-12) \\S() ALPHA(1-12) \\S() ALPHA(1-14) \\S() ALPHA(1-13) \\S() BUSINESS(3-25)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We see 13 patterns generated from row clusters with atleast 100 samples. Most \n",
    "# dominant patterns contain a _BUSINESS_ suffix except for patterns ranked 2, 3, 5 and 7.\n",
    "\n",
    "for i, gp in grouped_patterns.items():\n",
    "    if i != -1:\n",
    "        print(len(gp.top(pattern=True).idx))\n",
    "        print(i, gp.top())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Outliers\n",
    "\n",
    "Outliers are always a nuisance in data janitorial tasks. With Openclean_pattern, we empower an unconventional anomaly detection technique, i.e. using row patterns to detect mismatched entries. In this example, we discover two dominant patterns in the zipcode column: a digit, and a combination of alphanumeric characters. The latter only appears in the data in less than .1% values and hence can be regarded as outliers. Looking at these reveal that some canadian records sneaked into the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean_pattern.align.group import Group\n",
    "\n",
    "# create a new PatternFinder object with the group by length collector\n",
    "\n",
    "pf = PatternFinder(distinct=True,\n",
    "                    tokenizer=rt,\n",
    "                    collector=Group(),\n",
    "                    aligner=Padder()\n",
    "                  )\n",
    "column = 'Zip Code'\n",
    "patterns = pf.find(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1148\n",
      "1 DIGIT\n",
      "\n",
      "9\n",
      "3 ALPHANUM SPACE_REP ALPHANUM\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# looking at the patterns discovered in the zipcode column, we see there are 9 distinct values \n",
    "# that deviate from the rest of the column whereas the remainder 1148 distinct values follow a single\n",
    "# digit pattern\n",
    "\n",
    "for i, gp in patterns.items():\n",
    "    if i != -1:\n",
    "        print(len(gp.top(pattern=True).idx))\n",
    "        print(i, gp.top())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Business Name</th>\n",
       "      <th>Entity Type</th>\n",
       "      <th>Registry Date</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>Zip Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4538</th>\n",
       "      <td>MKII SERVICE, INC.</td>\n",
       "      <td>FOREIGN BUSINESS CORPORATION</td>\n",
       "      <td>07/14/2020</td>\n",
       "      <td>69 YONGE ST SUITE 600</td>\n",
       "      <td>TORONTO</td>\n",
       "      <td>M5E 1K3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4551</th>\n",
       "      <td>MK PAYMENT SOLUTIONS, INC.</td>\n",
       "      <td>FOREIGN BUSINESS CORPORATION</td>\n",
       "      <td>07/14/2020</td>\n",
       "      <td>69 YONGE ST SUITE 600</td>\n",
       "      <td>TORONTO</td>\n",
       "      <td>M5E 1K3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4562</th>\n",
       "      <td>MKII MARKETING, INC.</td>\n",
       "      <td>FOREIGN BUSINESS CORPORATION</td>\n",
       "      <td>07/14/2020</td>\n",
       "      <td>69 YONGE ST SUITE 600</td>\n",
       "      <td>TORONTO</td>\n",
       "      <td>M5E 1K3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5732</th>\n",
       "      <td>TASMAN AIR SERVICES LLC</td>\n",
       "      <td>DOMESTIC LIMITED LIABILITY COMPANY</td>\n",
       "      <td>07/16/2020</td>\n",
       "      <td>#5 4340 KING ST</td>\n",
       "      <td>DELTA</td>\n",
       "      <td>V4K 0A5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5949</th>\n",
       "      <td>SLANG WORLDWIDE INC.</td>\n",
       "      <td>FOREIGN BUSINESS CORPORATION</td>\n",
       "      <td>07/17/2020</td>\n",
       "      <td>50 CARROLL STREET</td>\n",
       "      <td>TORONTO</td>\n",
       "      <td>M4M 3G3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5992</th>\n",
       "      <td>TPD RESOURCES, INC.</td>\n",
       "      <td>FOREIGN BUSINESS CORPORATION</td>\n",
       "      <td>07/17/2020</td>\n",
       "      <td>980 HOWE STREET</td>\n",
       "      <td>VANCOUVER</td>\n",
       "      <td>V6Z 0C8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6007</th>\n",
       "      <td>QUARTECH CORRECTIONS LLC</td>\n",
       "      <td>FOREIGN LIMITED LIABILITY COMPANY</td>\n",
       "      <td>07/17/2020</td>\n",
       "      <td>2889 12TH AVENUE E</td>\n",
       "      <td>VANCOUVER</td>\n",
       "      <td>V5M 4T5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7808</th>\n",
       "      <td>DESIGN TRANSPORT USA INC.</td>\n",
       "      <td>DOMESTIC BUSINESS CORPORATION</td>\n",
       "      <td>07/22/2020</td>\n",
       "      <td>8705 170 STREET</td>\n",
       "      <td>SURREY</td>\n",
       "      <td>V4N 5K8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7868</th>\n",
       "      <td>NOBLE FOODS NUTRITION USA INC.</td>\n",
       "      <td>FOREIGN BUSINESS CORPORATION</td>\n",
       "      <td>07/22/2020</td>\n",
       "      <td>250 AV AVRO</td>\n",
       "      <td>POINTE-CLAIRE</td>\n",
       "      <td>H9R 6B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7879</th>\n",
       "      <td>NOBLE FOODS NUTRITION USA HOLDINGS INC.</td>\n",
       "      <td>FOREIGN BUSINESS CORPORATION</td>\n",
       "      <td>07/22/2020</td>\n",
       "      <td>250 AV AVRO</td>\n",
       "      <td>POINTE-CLAIRE</td>\n",
       "      <td>H9R 6B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8412</th>\n",
       "      <td>CONNECTION HUB LLC</td>\n",
       "      <td>DOMESTIC LIMITED LIABILITY COMPANY</td>\n",
       "      <td>07/24/2020</td>\n",
       "      <td>418-11511 27 AVE NW</td>\n",
       "      <td>EDMONTON</td>\n",
       "      <td>T6J 7J8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10943</th>\n",
       "      <td>TNG MERCHANDISING</td>\n",
       "      <td>ASSUMED BUSINESS NAME</td>\n",
       "      <td>07/30/2020</td>\n",
       "      <td>1067 WEST CORDOVA STREET 18TH FLOOR</td>\n",
       "      <td>VANCOUVER</td>\n",
       "      <td>V6C 1C7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Business Name  \\\n",
       "4538                        MKII SERVICE, INC.   \n",
       "4551                MK PAYMENT SOLUTIONS, INC.   \n",
       "4562                      MKII MARKETING, INC.   \n",
       "5732                   TASMAN AIR SERVICES LLC   \n",
       "5949                      SLANG WORLDWIDE INC.   \n",
       "5992                       TPD RESOURCES, INC.   \n",
       "6007                  QUARTECH CORRECTIONS LLC   \n",
       "7808                 DESIGN TRANSPORT USA INC.   \n",
       "7868            NOBLE FOODS NUTRITION USA INC.   \n",
       "7879   NOBLE FOODS NUTRITION USA HOLDINGS INC.   \n",
       "8412                        CONNECTION HUB LLC   \n",
       "10943                        TNG MERCHANDISING   \n",
       "\n",
       "                              Entity Type Registry Date  \\\n",
       "4538         FOREIGN BUSINESS CORPORATION    07/14/2020   \n",
       "4551         FOREIGN BUSINESS CORPORATION    07/14/2020   \n",
       "4562         FOREIGN BUSINESS CORPORATION    07/14/2020   \n",
       "5732   DOMESTIC LIMITED LIABILITY COMPANY    07/16/2020   \n",
       "5949         FOREIGN BUSINESS CORPORATION    07/17/2020   \n",
       "5992         FOREIGN BUSINESS CORPORATION    07/17/2020   \n",
       "6007    FOREIGN LIMITED LIABILITY COMPANY    07/17/2020   \n",
       "7808        DOMESTIC BUSINESS CORPORATION    07/22/2020   \n",
       "7868         FOREIGN BUSINESS CORPORATION    07/22/2020   \n",
       "7879         FOREIGN BUSINESS CORPORATION    07/22/2020   \n",
       "8412   DOMESTIC LIMITED LIABILITY COMPANY    07/24/2020   \n",
       "10943               ASSUMED BUSINESS NAME    07/30/2020   \n",
       "\n",
       "                                  Address            City Zip Code  \n",
       "4538                 69 YONGE ST SUITE 600        TORONTO  M5E 1K3  \n",
       "4551                 69 YONGE ST SUITE 600        TORONTO  M5E 1K3  \n",
       "4562                 69 YONGE ST SUITE 600        TORONTO  M5E 1K3  \n",
       "5732                       #5 4340 KING ST          DELTA  V4K 0A5  \n",
       "5949                     50 CARROLL STREET        TORONTO  M4M 3G3  \n",
       "5992                       980 HOWE STREET      VANCOUVER  V6Z 0C8  \n",
       "6007                    2889 12TH AVENUE E      VANCOUVER  V5M 4T5  \n",
       "7808                       8705 170 STREET         SURREY  V4N 5K8  \n",
       "7868                           250 AV AVRO  POINTE-CLAIRE  H9R 6B1  \n",
       "7879                           250 AV AVRO  POINTE-CLAIRE  H9R 6B1  \n",
       "8412                   418-11511 27 AVE NW       EDMONTON  T6J 7J8  \n",
       "10943  1067 WEST CORDOVA STREET 18TH FLOOR      VANCOUVER  V6C 1C7  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are canadian records\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "pred = np.logical_not(pf.compare(patterns[1].top(pattern=True), df[column]))\n",
    "df.loc[pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Basic Outliers\n",
    "\n",
    "This seems tricky but non-basic mismatches are automatically pushed out as noise with the heuristical hyperparameter optimization for the DBSCAN clusterer. Let's revisit non Basic Type resolution for Geospatial vocabulary from datamart_geo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openclean_pattern.datatypes.resolver import GeoSpatialResolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new DefaultTypeResolver object (identifies basic types)\n",
    "# intercepted by an Address and Geospatial Resolver (identify addresses and countries)\n",
    "\n",
    "dtr = DefaultTypeResolver(interceptors=[GeoSpatialResolver()])\n",
    "\n",
    "# create a new RegexTokenizer that'll tokenize the remaining values not identified by the type resolvers\n",
    "# on all delimiters\n",
    "\n",
    "rt = RegexTokenizer(type_resolver=dtr)\n",
    "\n",
    "# create a new PatternFinder object, use the tokenizer and play with the number of samples in the Clusterer collector\n",
    "\n",
    "column = 'City'\n",
    "city = df[column].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(_'ALPHA'_(9,'wenatchee'),),\n",
       " (_'ALPHA'_(6,'keizer'),),\n",
       " (_'ADMIN_1'_(8,'new york'),),\n",
       " (_'ADMIN_2'_(5,'salem'),),\n",
       " (_'ADMIN_1'_(8,'portland'),)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we type encode the city column, \n",
    "# notice how the tokens are now attached to an administrative level if found in the datamart_geo vocabulary\n",
    "\n",
    "enc = rt.encode(city)\n",
    "enc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we cluster with min_samples = 10, and align similar tokens\n",
    "\n",
    "gr = Cluster(min_samples=10).collect(enc)\n",
    "al = Padder().align(enc, gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and compile the patterns\n",
    "\n",
    "pn = DefaultRegexCompiler(method='row', per_group='all').compile(al, gr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[ALPHA(3-13)] 400 [0, 1, 5, 8, 9]\n",
      "\n",
      "1\n",
      "[ADMIN_LEVEL_1(4-12)] 13 [2, 163, 4, 584, 719]\n",
      "\n",
      "2\n",
      "[ADMIN_LEVEL_2(4-13)] 60 [129, 3, 259, 771, 7]\n",
      "\n",
      "3\n",
      "[ALPHA(2-8), SPACE_REP(1-1), ADMIN_LEVEL_4(5-8)] 16 [160, 450, 762, 644, 389]\n",
      "\n",
      "4\n",
      "[ADMIN_LEVEL_4(4-12)] 37 [128, 261, 646, 775, 10]\n",
      "\n",
      "5\n",
      "[ADMIN_LEVEL_3(4-13)] 50 [512, 258, 643, 394, 522]\n",
      "\n",
      "-1\n",
      "[ADMIN_LEVEL_3(4-9), SPACE_REP(1-1), ALPHA(4-7), GAP(0-0), GAP(0-0)] 8 [33, 16, 720, 84, 309]\n",
      "[ADMIN_LEVEL_1(3-9), SPACE_REP(1-1), ALPHA(4-7), GAP(0-0), GAP(0-0)] 9 [256, 41, 745, 746, 652]\n",
      "[ADMIN_LEVEL_0(7-7), GAP(0-0), GAP(0-0), GAP(0-0), GAP(0-0)] 1 [51]\n",
      "[ADMIN_LEVEL_2(6-9), SPACE_REP(1-1), ALPHA(5-7), GAP(0-0), GAP(0-0)] 9 [364, 716, 687, 315, 52]\n",
      "[ADMIN_LEVEL_1(5-11), SPACE_REP(1-1), ADMIN_LEVEL_2(4-4), GAP(0-0), GAP(0-0)] 4 [64, 271, 702, 215]\n",
      "[ADMIN_LEVEL_4(4-4), SPACE_REP(1-1), ADMIN_LEVEL_4(5-5), GAP(0-0), GAP(0-0)] 1 [93]\n",
      "[ADMIN_LEVEL_1(5-6), SPACE_REP(1-1), ADMIN_LEVEL_4(5-9), GAP(0-0), GAP(0-0)] 2 [248, 94]\n",
      "[ADMIN_LEVEL_2(4-8), SPACE_REP(1-1), ADMIN_LEVEL_2(4-8), GAP(0-0), GAP(0-0)] 4 [106, 755, 470, 167]\n",
      "[ALPHA(5-7), SPACE_REP(1-1), ADMIN_LEVEL_1(3-8), GAP(0-0), GAP(0-0)] 2 [114, 610]\n",
      "[ADMIN_LEVEL_4(4-8), SPACE_REP(1-1), ADMIN_LEVEL_2(4-7), GAP(0-0), GAP(0-0)] 4 [200, 122, 773, 154]\n",
      "[ADMIN_LEVEL_2(8-8), SPACE_REP(1-1), ADMIN_LEVEL_3(4-4), GAP(0-0), GAP(0-0)] 2 [393, 140]\n",
      "[ADMIN_LEVEL_3(4-4), SPACE_REP(1-1), ADMIN_LEVEL_3(4-4), SPACE_REP(1-1), ADMIN_LEVEL_2(4-4)] 1 [155]\n",
      "[ADMIN_LEVEL_4(4-8), SPACE_REP(1-1), ADMIN_LEVEL_3(4-7), GAP(0-0), GAP(0-0)] 3 [416, 514, 164]\n",
      "[ADMIN_LEVEL_1(5-5), SPACE_REP(1-1), ALPHA(4-4), SPACE_REP(1-1), ALPHA(5-5)] 1 [169]\n",
      "[ADMIN_LEVEL_3(4-4), SPACE_REP(1-1), ADMIN_LEVEL_4(5-9), GAP(0-0), GAP(0-0)] 4 [296, 466, 173, 414]\n",
      "[ALPHA(3-3), PUNCTUATION(1-1), ALPHA(1-1), SPACE_REP(1-1), ALPHA(6-6)] 1 [209]\n",
      "[ALPHA(3-3), SPACE_REP(1-1), ADMIN_LEVEL_4(5-5), SPACE_REP(1-1), ADMIN_LEVEL_2(7-7)] 1 [224]\n",
      "[ADMIN_LEVEL_5(6-9), GAP(0-0), GAP(0-0), GAP(0-0), GAP(0-0)] 4 [240, 660, 316, 397]\n",
      "[ADMIN_LEVEL_3(3-4), SPACE_REP(1-1), ADMIN_LEVEL_2(4-10), GAP(0-0), GAP(0-0)] 4 [361, 579, 291, 555]\n",
      "[ALPHA(3-3), SPACE_REP(1-1), ALPHA(7-7), SPACE_REP(1-1), ADMIN_LEVEL_2(7-7)] 1 [295]\n",
      "[ADMIN_LEVEL_3(3-6), SPACE_REP(1-1), ADMIN_LEVEL_3(4-6), GAP(0-0), GAP(0-0)] 6 [672, 417, 648, 426, 368]\n",
      "[ADMIN_LEVEL_3(4-4), SPACE_REP(1-1), ADMIN_LEVEL_1(4-6), GAP(0-0), GAP(0-0)] 2 [513, 434]\n",
      "[ALPHA(5-5), SPACE_REP(1-1), ALPHA(1-4), SPACE_REP(1-1), ALPHA(5-8)] 2 [448, 736]\n",
      "[ADMIN_LEVEL_3(4-4), SPACE_REP(1-1), ALPHA(2-4), SPACE_REP(1-1), ALPHA(4-5)] 2 [692, 478]\n",
      "[ADMIN_LEVEL_3(5-5), SPACE_REP(1-1), ADMIN_LEVEL_5(4-4), GAP(0-0), GAP(0-0)] 1 [611]\n",
      "[ALPHA(5-5), SPACE_REP(1-1), ALPHA(1-1), PUNCTUATION(1-1), ALPHA(5-5)] 1 [735]\n",
      "[ADMIN_LEVEL_1(5-5), SPACE_REP(1-1), ADMIN_LEVEL_3(3-3), SPACE_REP(1-1), ADMIN_LEVEL_2(7-7)] 1 [749]\n",
      "[ADMIN_LEVEL_2(6-6), SPACE_REP(1-1), ALPHA(3-3), SPACE_REP(1-1), ADMIN_LEVEL_2(3-3)] 1 [787]\n",
      "[ADMIN_LEVEL_3(7-7), PUNCTUATION(1-1), ADMIN_LEVEL_2(5-5), GAP(0-0), GAP(0-0)] 1 [791]\n",
      "\n",
      "6\n",
      "[ALPHA(1-8), SPACE_REP(1-1), ALPHA(3-10)] 75 [768, 769, 130, 265, 521]\n",
      "[ALPHA(6-6), PUNCTUATION(1-1), ALPHA(6-6)] 1 [638]\n",
      "\n",
      "7\n",
      "[ALPHA(2-9), SPACE_REP(1-1), ADMIN_LEVEL_3(3-7)] 25 [384, 520, 780, 409, 30]\n",
      "\n",
      "8\n",
      "[ALPHA(3-9), SPACE_REP(1-1), ADMIN_LEVEL_2(4-13)] 20 [257, 147, 790, 547, 168]\n",
      "\n",
      "9\n",
      "[ADMIN_LEVEL_4(4-6), SPACE_REP(1-1), ALPHA(4-9)] 11 [481, 323, 612, 264, 172]\n",
      "[ADMIN_LEVEL_4(6-6), PUNCTUATION(1-1), ALPHA(9-9)] 1 [445]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Upon inspection, we see cluster -1 (noise) has numerous patterns created from at max 8 patterns. Remember \n",
    "# we set min_samples in the clusterer to 10? We can potentially tweak that hyperparameter to decrease/increase the \n",
    "# noise threshold. We also realize how important it can be to have the typeresolver produce correct mappings. e.g.\n",
    "# many of the values categorized as noise are rows that partially matched the master vocabulary, and hence\n",
    "# this depicts how this is a two way street. We should also consider the respective type resolver with the \n",
    "# values mis-categorized as noise.\n",
    "\n",
    "for i, pnn in pn.items():\n",
    "    print(i)\n",
    "    for pat in pnn.values():\n",
    "        print(pat, pat.freq, list(pat.idx)[:5])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEBANON\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Business Name</th>\n",
       "      <th>Entity Type</th>\n",
       "      <th>Registry Date</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>Zip Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>VESSEL MUSIC GROUP LLC</td>\n",
       "      <td>DOMESTIC LIMITED LIABILITY COMPANY</td>\n",
       "      <td>07/01/2020</td>\n",
       "      <td>755 E ASH ST</td>\n",
       "      <td>LEBANON</td>\n",
       "      <td>97355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>VESSEL MUSIC GROUP LLC</td>\n",
       "      <td>DOMESTIC LIMITED LIABILITY COMPANY</td>\n",
       "      <td>07/01/2020</td>\n",
       "      <td>1200 E GRANT ST STE E</td>\n",
       "      <td>LEBANON</td>\n",
       "      <td>97355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>SONS OF STONE CARPENTRY LLC</td>\n",
       "      <td>DOMESTIC LIMITED LIABILITY COMPANY</td>\n",
       "      <td>07/02/2020</td>\n",
       "      <td>475 W ASH ST</td>\n",
       "      <td>LEBANON</td>\n",
       "      <td>97355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>BEAUTY MARKED BY MICHELLE MARKS</td>\n",
       "      <td>ASSUMED BUSINESS NAME</td>\n",
       "      <td>07/02/2020</td>\n",
       "      <td>971 E GRANT ST</td>\n",
       "      <td>LEBANON</td>\n",
       "      <td>97355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>BEAUTY MARKED BY MICHELLE MARKS</td>\n",
       "      <td>ASSUMED BUSINESS NAME</td>\n",
       "      <td>07/02/2020</td>\n",
       "      <td>455 S MAIN ST</td>\n",
       "      <td>LEBANON</td>\n",
       "      <td>97355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Business Name                         Entity Type  \\\n",
       "133           VESSEL MUSIC GROUP LLC  DOMESTIC LIMITED LIABILITY COMPANY   \n",
       "134           VESSEL MUSIC GROUP LLC  DOMESTIC LIMITED LIABILITY COMPANY   \n",
       "599      SONS OF STONE CARPENTRY LLC  DOMESTIC LIMITED LIABILITY COMPANY   \n",
       "780  BEAUTY MARKED BY MICHELLE MARKS               ASSUMED BUSINESS NAME   \n",
       "781  BEAUTY MARKED BY MICHELLE MARKS               ASSUMED BUSINESS NAME   \n",
       "\n",
       "    Registry Date               Address      City Zip Code  \n",
       "133    07/01/2020           755 E ASH ST  LEBANON    97355  \n",
       "134    07/01/2020  1200 E GRANT ST STE E  LEBANON    97355  \n",
       "599    07/02/2020           475 W ASH ST  LEBANON    97355  \n",
       "780    07/02/2020         971 E GRANT ST  LEBANON    97355  \n",
       "781    07/02/2020          455 S MAIN ST  LEBANON    97355  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at the noisy data, one of the things that stands out is ADMIN_0, which is usually reserved for \n",
    "# country names. False alarm!\n",
    "\n",
    "print(city.iloc[51]) #51 is the index of admin_0 above\n",
    "df[df['City']==city.iloc[51]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "997             LEE'S SUMMIT\n",
       "1086       ELK GROVE VILLAGE\n",
       "4020     MOUNT HOOD PARKDALE\n",
       "10056          COEUR D ALENE\n",
       "10055          COEUR D'ALENE\n",
       "Name: City, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Other values that standout to me are those that were not even partially type resolved inside the noise cluster\n",
    "# The type resolvers strip all punctuation to perform partial string matching so perhaps more preprocessing\n",
    "# is a suggestion here\n",
    "\n",
    "city.iloc[[209, 224, 448, 736, 735]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7868    POINTE-CLAIRE\n",
      "Name: City, dtype: object\n",
      "\n",
      "3911    MILTON-FREEWATER\n",
      "Name: City, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Also it might be worth looking at the smaller single patterns inside cluster 6 and 9\n",
    "# Again these values are legitimate values so maybe the easiest fix to align with the rest of the \n",
    "# group could be removing the dashes\n",
    "\n",
    "print(city.iloc[list(pn[6].top(2, pattern=True).idx)])\n",
    "print()\n",
    "print(city.iloc[list(pn[9].top(2, pattern=True).idx)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________________________________________________________________________________________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
