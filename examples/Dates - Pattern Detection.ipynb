{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying patterns in a date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2015-16\n",
       "5       2012-13\n",
       "46       FY2019\n",
       "31    2009-2010\n",
       "13      2013/14\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = pd.read_csv('../resources/dev/dates.txt', header=None, squeeze=True)\n",
    "dates.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2015', '-', '16'],\n",
       " ['2016', '-', '17'],\n",
       " ['2017', '-', '18'],\n",
       " ['2014', '-', '15'],\n",
       " ['2013', '-', '14'],\n",
       " ['2012', '-', '13'],\n",
       " ['2015', '/', '16'],\n",
       " ['2016', '/', '17'],\n",
       " ['2011', '-', '12'],\n",
       " ['2014', '/', '15'],\n",
       " ['2017', '/', '18'],\n",
       " ['2010', '-', '11'],\n",
       " ['2012', '/', '13'],\n",
       " ['2013', '/', '14'],\n",
       " ['2018', '-', '19'],\n",
       " ['2013', '-', '2014'],\n",
       " ['2015', '-', '2016'],\n",
       " ['2011', '-', '2013'],\n",
       " ['2013', '-', '2015'],\n",
       " ['2015', '-', '2017'],\n",
       " ['2009', '-', '2011'],\n",
       " ['2012', '-', '2014'],\n",
       " ['2014', '-', '2016'],\n",
       " ['2016', '-', '2017'],\n",
       " ['2010', '-', '2012'],\n",
       " ['2011', '-', '2012'],\n",
       " ['2014', '-', '2015'],\n",
       " ['2010', '-', '2011'],\n",
       " ['2011', '/', '12'],\n",
       " ['2012', '-', '2013'],\n",
       " ['2007', '-', '2008'],\n",
       " ['2009', '-', '2010'],\n",
       " ['2010', '/', '11'],\n",
       " ['2017', '-', '2018'],\n",
       " ['2008', '-', '2009'],\n",
       " ['2009', '/', '10'],\n",
       " ['2011', '–', '12'],\n",
       " ['2006', '-', '2007'],\n",
       " ['2007', '-', '2009'],\n",
       " ['2008', '-', '2010'],\n",
       " ['2013', '–', '14'],\n",
       " ['2014', '–', '15'],\n",
       " ['2015', '–', '16'],\n",
       " ['2018', '/', '19'],\n",
       " ['fy2016'],\n",
       " ['fy2017'],\n",
       " ['fy2019'],\n",
       " ['2007', '-', '08'],\n",
       " ['2008', '/', '09'],\n",
       " ['2009', '-', '10'],\n",
       " ['2009', '–', '10'],\n",
       " ['2010', '–', '11'],\n",
       " ['2012', '–', '13'],\n",
       " ['2016', '-', '2018'],\n",
       " ['2016', '–', '17'],\n",
       " ['2017', '-', '2019'],\n",
       " ['2018', '-', '2019'],\n",
       " ['2018', '-', '2020'],\n",
       " ['2019', '-', '2021'],\n",
       " ['fy', ' ', '2015'],\n",
       " ['fy2018']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the column\n",
    "from openclean_pattern.tokenize.factory import TokenizerFactory\n",
    "tokenizer = TokenizerFactory.create_tokenizer('default')\n",
    "tokenizer.encode(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2015', '-', '16'],\n",
       " ['2016', '-', '17'],\n",
       " ['2017', '-', '18'],\n",
       " ['2014', '-', '15'],\n",
       " ['2013', '-', '14'],\n",
       " ['2012', '-', '13'],\n",
       " ['2015', '/', '16'],\n",
       " ['2016', '/', '17'],\n",
       " ['2011', '-', '12'],\n",
       " ['2014', '/', '15'],\n",
       " ['2017', '/', '18'],\n",
       " ['2010', '-', '11'],\n",
       " ['2012', '/', '13'],\n",
       " ['2013', '/', '14'],\n",
       " ['2018', '-', '19'],\n",
       " ['2013', '-', '2014'],\n",
       " ['2015', '-', '2016'],\n",
       " ['2011', '-', '2013'],\n",
       " ['2013', '-', '2015'],\n",
       " ['2015', '-', '2017'],\n",
       " ['2009', '-', '2011'],\n",
       " ['2012', '-', '2014'],\n",
       " ['2014', '-', '2016'],\n",
       " ['2016', '-', '2017'],\n",
       " ['2010', '-', '2012'],\n",
       " ['2011', '-', '2012'],\n",
       " ['2014', '-', '2015'],\n",
       " ['2010', '-', '2011'],\n",
       " ['2011', '/', '12'],\n",
       " ['2012', '-', '2013'],\n",
       " ['2007', '-', '2008'],\n",
       " ['2009', '-', '2010'],\n",
       " ['2010', '/', '11'],\n",
       " ['2017', '-', '2018'],\n",
       " ['2008', '-', '2009'],\n",
       " ['2009', '/', '10'],\n",
       " ['2011', '–', '12'],\n",
       " ['2006', '-', '2007'],\n",
       " ['2007', '-', '2009'],\n",
       " ['2008', '-', '2010'],\n",
       " ['2013', '–', '14'],\n",
       " ['2014', '–', '15'],\n",
       " ['2015', '–', '16'],\n",
       " ['2018', '/', '19'],\n",
       " ['fy2016'],\n",
       " ['fy2017'],\n",
       " ['fy2019'],\n",
       " ['2007', '-', '08'],\n",
       " ['2008', '/', '09'],\n",
       " ['2009', '-', '10'],\n",
       " ['2009', '–', '10'],\n",
       " ['2010', '–', '11'],\n",
       " ['2012', '–', '13'],\n",
       " ['2016', '-', '2018'],\n",
       " ['2016', '–', '17'],\n",
       " ['2017', '-', '2019'],\n",
       " ['2018', '-', '2019'],\n",
       " ['2018', '-', '2020'],\n",
       " ['2019', '-', '2021'],\n",
       " ['fy', ' ', '2015'],\n",
       " ['fy2018']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize and convert column into internal token representations\n",
    "enc = tokenizer.encode(dates)\n",
    "enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect similar rows together\n",
    "\n",
    "# from openclean_pattern.align.factory import CollectorFactory\n",
    "# collector = CollectorFactory.create_collector('cluster')\n",
    "\n",
    "from openclean_pattern.collect.cluster import Cluster\n",
    "collector = Cluster(min_samples=1)\n",
    "\n",
    "col = collector.collect(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {0: [0,\n",
       "              1,\n",
       "              2,\n",
       "              3,\n",
       "              4,\n",
       "              5,\n",
       "              6,\n",
       "              7,\n",
       "              8,\n",
       "              9,\n",
       "              10,\n",
       "              11,\n",
       "              12,\n",
       "              13,\n",
       "              14,\n",
       "              15,\n",
       "              16,\n",
       "              17,\n",
       "              18,\n",
       "              19,\n",
       "              20,\n",
       "              21,\n",
       "              22,\n",
       "              23,\n",
       "              24,\n",
       "              25,\n",
       "              26,\n",
       "              27,\n",
       "              28,\n",
       "              29,\n",
       "              30,\n",
       "              31,\n",
       "              32,\n",
       "              33,\n",
       "              34,\n",
       "              35,\n",
       "              36,\n",
       "              37,\n",
       "              38,\n",
       "              39,\n",
       "              40,\n",
       "              41,\n",
       "              42,\n",
       "              43,\n",
       "              47,\n",
       "              48,\n",
       "              49,\n",
       "              50,\n",
       "              51,\n",
       "              52,\n",
       "              53,\n",
       "              54,\n",
       "              55,\n",
       "              56,\n",
       "              57,\n",
       "              58],\n",
       "             1: [44, 45, 46, 60],\n",
       "             2: [59]})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoded rows clustered together. -1 is noise but doesnt exist because we set min_samples=1 in dbscan\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['2015', '-', '16']\n",
      "['2016', '-', '17']\n",
      "['2017', '-', '18']\n",
      "['2014', '-', '15']\n",
      "['2013', '-', '14']\n",
      "['2012', '-', '13']\n",
      "['2015', '/', '16']\n",
      "\n",
      "1\n",
      "['fy2016']\n",
      "['fy2017']\n",
      "['fy2019']\n",
      "['fy2018']\n",
      "\n",
      "2\n",
      "['fy', ' ', '2015']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Samples of encoded rows in each cluster\n",
    "for j in col:\n",
    "    print(j)\n",
    "    for n, i in enumerate(col[j]):\n",
    "        print(enc[i])\n",
    "        if n > 5:\n",
    "            break\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile patterns in each cluster\n",
    "from openclean_pattern.regex.compiler import DefaultRegexCompiler\n",
    "\n",
    "compiler = DefaultRegexCompiler()\n",
    "compiled = compiler.compile(enc, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: RowPatterns(NUMERIC PUNC NUMERIC),\n",
       " 1: RowPatterns(ALPHANUM),\n",
       " 2: RowPatterns(ALPHA \\S NUMERIC)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 defaultdict(<class 'float'>, {'NUMERIC PUNC NUMERIC': 1.0})\n",
      "1 defaultdict(<class 'float'>, {'ALPHANUM': 1.0})\n",
      "2 defaultdict(<class 'float'>, {'ALPHA \\\\S NUMERIC': 1.0})\n"
     ]
    }
   ],
   "source": [
    "# Coverage of patterns in each cluster\n",
    "for k, pattern in compiled.items():\n",
    "    print(k, pattern.stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (openclean-core)",
   "language": "python",
   "name": "pycharm-c6d12a8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
