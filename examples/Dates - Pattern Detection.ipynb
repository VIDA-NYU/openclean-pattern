{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying patterns in a date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2015-16\n",
       "5       2012-13\n",
       "46       FY2019\n",
       "31    2009-2010\n",
       "13      2013/14\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = pd.read_csv('../resources/dev/dates.txt', header=None, squeeze=True)\n",
    "dates.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2015', '-', '16'),\n",
       " ('2016', '-', '17'),\n",
       " ('2017', '-', '18'),\n",
       " ('2014', '-', '15'),\n",
       " ('2013', '-', '14'),\n",
       " ('2012', '-', '13'),\n",
       " ('2015', '/', '16'),\n",
       " ('2016', '/', '17'),\n",
       " ('2011', '-', '12'),\n",
       " ('2014', '/', '15'),\n",
       " ('2017', '/', '18'),\n",
       " ('2010', '-', '11'),\n",
       " ('2012', '/', '13'),\n",
       " ('2013', '/', '14'),\n",
       " ('2018', '-', '19'),\n",
       " ('2013', '-', '2014'),\n",
       " ('2015', '-', '2016'),\n",
       " ('2011', '-', '2013'),\n",
       " ('2013', '-', '2015'),\n",
       " ('2015', '-', '2017'),\n",
       " ('2009', '-', '2011'),\n",
       " ('2012', '-', '2014'),\n",
       " ('2014', '-', '2016'),\n",
       " ('2016', '-', '2017'),\n",
       " ('2010', '-', '2012'),\n",
       " ('2011', '-', '2012'),\n",
       " ('2014', '-', '2015'),\n",
       " ('2010', '-', '2011'),\n",
       " ('2011', '/', '12'),\n",
       " ('2012', '-', '2013'),\n",
       " ('2007', '-', '2008'),\n",
       " ('2009', '-', '2010'),\n",
       " ('2010', '/', '11'),\n",
       " ('2017', '-', '2018'),\n",
       " ('2008', '-', '2009'),\n",
       " ('2009', '/', '10'),\n",
       " ('2011', '–', '12'),\n",
       " ('2006', '-', '2007'),\n",
       " ('2007', '-', '2009'),\n",
       " ('2008', '-', '2010'),\n",
       " ('2013', '–', '14'),\n",
       " ('2014', '–', '15'),\n",
       " ('2015', '–', '16'),\n",
       " ('2018', '/', '19'),\n",
       " ('fy2016',),\n",
       " ('fy2017',),\n",
       " ('fy2019',),\n",
       " ('2007', '-', '08'),\n",
       " ('2008', '/', '09'),\n",
       " ('2009', '-', '10'),\n",
       " ('2009', '–', '10'),\n",
       " ('2010', '–', '11'),\n",
       " ('2012', '–', '13'),\n",
       " ('2016', '-', '2018'),\n",
       " ('2016', '–', '17'),\n",
       " ('2017', '-', '2019'),\n",
       " ('2018', '-', '2019'),\n",
       " ('2018', '-', '2020'),\n",
       " ('2019', '-', '2021'),\n",
       " ('fy', ' ', '2015'),\n",
       " ('fy2018',)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the column\n",
    "from openclean_pattern.tokenize.factory import TokenizerFactory\n",
    "tokenizer = TokenizerFactory.create_tokenizer('default')\n",
    "tokenizer.tokenize(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(_'NUMERIC'_(4,'2015'), _'PUNC'_(1,'-'), _'NUMERIC'_(2,'16')),\n",
       " (_'NUMERIC'_(4,'2016'), _'PUNC'_(1,'-'), _'NUMERIC'_(2,'17')),\n",
       " (_'NUMERIC'_(4,'2017'), _'PUNC'_(1,'-'), _'NUMERIC'_(2,'18')),\n",
       " (_'NUMERIC'_(4,'2014'), _'PUNC'_(1,'-'), _'NUMERIC'_(2,'15')),\n",
       " (_'NUMERIC'_(4,'2013'), _'PUNC'_(1,'-'), _'NUMERIC'_(2,'14')),\n",
       " (_'NUMERIC'_(4,'2012'), _'PUNC'_(1,'-'), _'NUMERIC'_(2,'13')),\n",
       " (_'NUMERIC'_(4,'2015'), _'PUNC'_(1,'/'), _'NUMERIC'_(2,'16')),\n",
       " (_'NUMERIC'_(4,'2016'), _'PUNC'_(1,'/'), _'NUMERIC'_(2,'17')),\n",
       " (_'NUMERIC'_(4,'2011'), _'PUNC'_(1,'-'), _'NUMERIC'_(2,'12')),\n",
       " (_'NUMERIC'_(4,'2014'), _'PUNC'_(1,'/'), _'NUMERIC'_(2,'15')),\n",
       " (_'NUMERIC'_(4,'2017'), _'PUNC'_(1,'/'), _'NUMERIC'_(2,'18')),\n",
       " (_'NUMERIC'_(4,'2010'), _'PUNC'_(1,'-'), _'NUMERIC'_(2,'11')),\n",
       " (_'NUMERIC'_(4,'2012'), _'PUNC'_(1,'/'), _'NUMERIC'_(2,'13')),\n",
       " (_'NUMERIC'_(4,'2013'), _'PUNC'_(1,'/'), _'NUMERIC'_(2,'14')),\n",
       " (_'NUMERIC'_(4,'2018'), _'PUNC'_(1,'-'), _'NUMERIC'_(2,'19')),\n",
       " (_'NUMERIC'_(4,'2013'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2014')),\n",
       " (_'NUMERIC'_(4,'2015'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2016')),\n",
       " (_'NUMERIC'_(4,'2011'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2013')),\n",
       " (_'NUMERIC'_(4,'2013'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2015')),\n",
       " (_'NUMERIC'_(4,'2015'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2017')),\n",
       " (_'NUMERIC'_(4,'2009'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2011')),\n",
       " (_'NUMERIC'_(4,'2012'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2014')),\n",
       " (_'NUMERIC'_(4,'2014'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2016')),\n",
       " (_'NUMERIC'_(4,'2016'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2017')),\n",
       " (_'NUMERIC'_(4,'2010'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2012')),\n",
       " (_'NUMERIC'_(4,'2011'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2012')),\n",
       " (_'NUMERIC'_(4,'2014'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2015')),\n",
       " (_'NUMERIC'_(4,'2010'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2011')),\n",
       " (_'NUMERIC'_(4,'2011'), _'PUNC'_(1,'/'), _'NUMERIC'_(2,'12')),\n",
       " (_'NUMERIC'_(4,'2012'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2013')),\n",
       " (_'NUMERIC'_(4,'2007'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2008')),\n",
       " (_'NUMERIC'_(4,'2009'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2010')),\n",
       " (_'NUMERIC'_(4,'2010'), _'PUNC'_(1,'/'), _'NUMERIC'_(2,'11')),\n",
       " (_'NUMERIC'_(4,'2017'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2018')),\n",
       " (_'NUMERIC'_(4,'2008'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2009')),\n",
       " (_'NUMERIC'_(4,'2009'), _'PUNC'_(1,'/'), _'NUMERIC'_(2,'10')),\n",
       " (_'NUMERIC'_(4,'2011'), _'PUNC'_(1,'–'), _'NUMERIC'_(2,'12')),\n",
       " (_'NUMERIC'_(4,'2006'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2007')),\n",
       " (_'NUMERIC'_(4,'2007'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2009')),\n",
       " (_'NUMERIC'_(4,'2008'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2010')),\n",
       " (_'NUMERIC'_(4,'2013'), _'PUNC'_(1,'–'), _'NUMERIC'_(2,'14')),\n",
       " (_'NUMERIC'_(4,'2014'), _'PUNC'_(1,'–'), _'NUMERIC'_(2,'15')),\n",
       " (_'NUMERIC'_(4,'2015'), _'PUNC'_(1,'–'), _'NUMERIC'_(2,'16')),\n",
       " (_'NUMERIC'_(4,'2018'), _'PUNC'_(1,'/'), _'NUMERIC'_(2,'19')),\n",
       " (_'ALPHANUM'_(6,'fy2016'),),\n",
       " (_'ALPHANUM'_(6,'fy2017'),),\n",
       " (_'ALPHANUM'_(6,'fy2019'),),\n",
       " (_'NUMERIC'_(4,'2007'), _'PUNC'_(1,'-'), _'NUMERIC'_(2,'08')),\n",
       " (_'NUMERIC'_(4,'2008'), _'PUNC'_(1,'/'), _'NUMERIC'_(2,'09')),\n",
       " (_'NUMERIC'_(4,'2009'), _'PUNC'_(1,'-'), _'NUMERIC'_(2,'10')),\n",
       " (_'NUMERIC'_(4,'2009'), _'PUNC'_(1,'–'), _'NUMERIC'_(2,'10')),\n",
       " (_'NUMERIC'_(4,'2010'), _'PUNC'_(1,'–'), _'NUMERIC'_(2,'11')),\n",
       " (_'NUMERIC'_(4,'2012'), _'PUNC'_(1,'–'), _'NUMERIC'_(2,'13')),\n",
       " (_'NUMERIC'_(4,'2016'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2018')),\n",
       " (_'NUMERIC'_(4,'2016'), _'PUNC'_(1,'–'), _'NUMERIC'_(2,'17')),\n",
       " (_'NUMERIC'_(4,'2017'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2019')),\n",
       " (_'NUMERIC'_(4,'2018'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2019')),\n",
       " (_'NUMERIC'_(4,'2018'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2020')),\n",
       " (_'NUMERIC'_(4,'2019'), _'PUNC'_(1,'-'), _'NUMERIC'_(4,'2021')),\n",
       " (_'ALPHA'_(2,'fy'), _'\\\\S'_(1,' '), _'NUMERIC'_(4,'2015')),\n",
       " (_'ALPHANUM'_(6,'fy2018'),)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize and convert column into internal token representations\n",
    "enc = tokenizer.encode(dates)\n",
    "enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect similar rows together\n",
    "\n",
    "# from openclean_pattern.align.factory import CollectorFactory\n",
    "# collector = CollectorFactory.create_collector('cluster')\n",
    "\n",
    "from openclean_pattern.align.cluster import Cluster\n",
    "collector = Cluster(min_samples=1)\n",
    "\n",
    "col = collector.collect(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {0: [0,\n",
       "              1,\n",
       "              2,\n",
       "              3,\n",
       "              4,\n",
       "              5,\n",
       "              6,\n",
       "              7,\n",
       "              8,\n",
       "              9,\n",
       "              10,\n",
       "              11,\n",
       "              12,\n",
       "              13,\n",
       "              14,\n",
       "              15,\n",
       "              16,\n",
       "              17,\n",
       "              18,\n",
       "              19,\n",
       "              20,\n",
       "              21,\n",
       "              22,\n",
       "              23,\n",
       "              24,\n",
       "              25,\n",
       "              26,\n",
       "              27,\n",
       "              28,\n",
       "              29,\n",
       "              30,\n",
       "              31,\n",
       "              32,\n",
       "              33,\n",
       "              34,\n",
       "              35,\n",
       "              36,\n",
       "              37,\n",
       "              38,\n",
       "              39,\n",
       "              40,\n",
       "              41,\n",
       "              42,\n",
       "              43,\n",
       "              47,\n",
       "              48,\n",
       "              49,\n",
       "              50,\n",
       "              51,\n",
       "              52,\n",
       "              53,\n",
       "              54,\n",
       "              55,\n",
       "              56,\n",
       "              57,\n",
       "              58],\n",
       "             1: [44, 45, 46, 60],\n",
       "             2: [59]})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoded rows clustered together. -1 is noise but doesnt exist because we set min_samples=1 in dbscan\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(_'NUMERIC'_(4,'2015'), _'PUNC'_(1,'-'), _'NUMERIC'_(2,'16'))\n",
      "(_'NUMERIC'_(4,'2016'), _'PUNC'_(1,'-'), _'NUMERIC'_(2,'17'))\n",
      "(_'NUMERIC'_(4,'2017'), _'PUNC'_(1,'-'), _'NUMERIC'_(2,'18'))\n",
      "(_'NUMERIC'_(4,'2014'), _'PUNC'_(1,'-'), _'NUMERIC'_(2,'15'))\n",
      "(_'NUMERIC'_(4,'2013'), _'PUNC'_(1,'-'), _'NUMERIC'_(2,'14'))\n",
      "(_'NUMERIC'_(4,'2012'), _'PUNC'_(1,'-'), _'NUMERIC'_(2,'13'))\n",
      "(_'NUMERIC'_(4,'2015'), _'PUNC'_(1,'/'), _'NUMERIC'_(2,'16'))\n",
      "\n",
      "1\n",
      "(_'ALPHANUM'_(6,'fy2016'),)\n",
      "(_'ALPHANUM'_(6,'fy2017'),)\n",
      "(_'ALPHANUM'_(6,'fy2019'),)\n",
      "(_'ALPHANUM'_(6,'fy2018'),)\n",
      "\n",
      "2\n",
      "(_'ALPHA'_(2,'fy'), _'\\\\S'_(1,' '), _'NUMERIC'_(4,'2015'))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Samples of encoded rows in each cluster\n",
    "for j in col:\n",
    "    print(j)\n",
    "    for n, i in enumerate(col[j]):\n",
    "        print(enc[i])\n",
    "        if n > 5:\n",
    "            break\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile patterns in each cluster\n",
    "from openclean_pattern.regex.compiler import DefaultRegexCompiler\n",
    "\n",
    "compiler = DefaultRegexCompiler()\n",
    "compiled = compiler.compile(enc, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: RowPatterns(DIGIT PUNCTUATION DIGIT),\n",
       " 1: RowPatterns(ALPHANUM),\n",
       " 2: RowPatterns(ALPHA SPACE_REP DIGIT)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 defaultdict(<class 'float'>, {'DIGIT PUNCTUATION DIGIT': 1.0})\n",
      "1 defaultdict(<class 'float'>, {'ALPHANUM': 1.0})\n",
      "2 defaultdict(<class 'float'>, {'ALPHA SPACE_REP DIGIT': 1.0})\n"
     ]
    }
   ],
   "source": [
    "# Coverage of patterns in each cluster\n",
    "for k, pattern in compiled.items():\n",
    "    print(k, pattern.stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
